{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 16295,
          "databundleVersionId": 1099992,
          "sourceType": "competition"
        },
        {
          "sourceId": 13802753,
          "sourceType": "datasetVersion",
          "datasetId": 8788373
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "557yUGTotzPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "DATA_PATH = \"/kaggle/input/tweet-sentiment-extraction\"\n",
        "\n",
        "train_df = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
        "test_df  = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
        "print(train_df.shape, test_df.shape)\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:03.260605Z",
          "iopub.execute_input": "2025-11-20T14:14:03.261162Z",
          "iopub.status.idle": "2025-11-20T14:14:04.275637Z",
          "shell.execute_reply.started": "2025-11-20T14:14:03.261136Z",
          "shell.execute_reply": "2025-11-20T14:14:04.275086Z"
        },
        "id": "-Wg_JNgCrANv",
        "outputId": "cdc2603b-f2b7-4b96-f02e-20973dfc8a49"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "(27481, 4) (3534, 3)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment  \n0  I`d have responded, if I were going   neutral  \n1                             Sooo SAD  negative  \n2                          bullying me  negative  \n3                       leave me alone  negative  \n4                        Sons of ****,  negative  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def clean_text_light(s):\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    return s.strip()\n",
        "\n",
        "def clean_selected_text(s):\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = s.strip()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "train_df[\"text\"] = train_df[\"text\"].astype(str).apply(clean_text_light)\n",
        "train_df[\"selected_text\"] = train_df[\"selected_text\"].astype(str).apply(clean_selected_text)\n",
        "test_df[\"text\"] = test_df[\"text\"].astype(str).apply(clean_text_light)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:06.508404Z",
          "iopub.execute_input": "2025-11-20T14:14:06.508899Z",
          "iopub.status.idle": "2025-11-20T14:14:06.761079Z",
          "shell.execute_reply.started": "2025-11-20T14:14:06.508874Z",
          "shell.execute_reply": "2025-11-20T14:14:06.760275Z"
        },
        "id": "zGNMsNYhrANx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"text_len\"] = train_df[\"text\"].str.len()\n",
        "train_df[\"sel_len\"] = train_df[\"selected_text\"].str.len()\n",
        "train_df[[\"text\", \"selected_text\", \"text_len\", \"sel_len\"]].head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:10.004009Z",
          "iopub.execute_input": "2025-11-20T14:14:10.004583Z",
          "iopub.status.idle": "2025-11-20T14:14:10.038863Z",
          "shell.execute_reply.started": "2025-11-20T14:14:10.004559Z",
          "shell.execute_reply": "2025-11-20T14:14:10.038115Z"
        },
        "id": "SPh4vq1JrANy",
        "outputId": "1237ff59-3536-4a9c-a867-68352e797b1f"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                text  \\\n0                I`d have responded, if I were going   \n1      Sooo SAD I will miss you here in San Diego!!!   \n2                          my boss is bullying me...   \n3                     what interview! leave me alone   \n4  Sons of ****, why couldn`t they put them on th...   \n\n                         selected_text  text_len  sel_len  \n0  I`d have responded, if I were going        35       35  \n1                             Sooo SAD        45        8  \n2                          bullying me        25       11  \n3                       leave me alone        30       14  \n4                        Sons of ****,        74       13  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>text_len</th>\n      <th>sel_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>35</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>45</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>25</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>30</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on th...</td>\n      <td>Sons of ****,</td>\n      <td>74</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def find_selected_span(row):\n",
        "    text = row[\"text\"]\n",
        "    selected = row[\"selected_text\"]\n",
        "\n",
        "    # nếu 2 chuỗi giống hệt, span = toàn bộ câu\n",
        "    if text == selected:\n",
        "        return 0, len(text)\n",
        "\n",
        "    # tìm vị trí substring (có thể có nhiều, nên chọn cái nào Jaccard tốt nhất)\n",
        "    idx = text.find(selected)\n",
        "    if idx != -1:\n",
        "        return idx, idx + len(selected)\n",
        "\n",
        "    # Nếu không find được -> cố gắng nới lỏng chút (hay bị khi có space/thừa/kí tự đặc biệt)\n",
        "    # Chiến lược đơn giản: lower-case, bỏ space dư\n",
        "    text_low = text.lower()\n",
        "    sel_low = selected.lower().strip()\n",
        "    idx = text_low.find(sel_low)\n",
        "    if idx != -1:\n",
        "        return idx, idx + len(sel_low)\n",
        "\n",
        "    # Nếu vẫn không tìm được, tạm trả -1 để sau dễ debug\n",
        "    return -1, -1\n",
        "\n",
        "# áp dụng\n",
        "span_indices = train_df.apply(find_selected_span, axis=1)\n",
        "train_df[\"char_start\"] = span_indices.apply(lambda x: x[0])\n",
        "train_df[\"char_end\"] = span_indices.apply(lambda x: x[1])\n",
        "\n",
        "# xem có bao nhiêu dòng bị lỗi (không tìm thấy selected_text trong text)\n",
        "bad_rows = train_df[train_df[\"char_start\"] == -1]\n",
        "print(\"Số dòng không tìm được span:\", len(bad_rows))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:12.292443Z",
          "iopub.execute_input": "2025-11-20T14:14:12.293183Z",
          "iopub.status.idle": "2025-11-20T14:14:12.489559Z",
          "shell.execute_reply.started": "2025-11-20T14:14:12.293148Z",
          "shell.execute_reply": "2025-11-20T14:14:12.488701Z"
        },
        "id": "Y5TZ7-WwrANy",
        "outputId": "9856cc6f-c0a4-4c43-a5e5-f4c8b6c9d300"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Số dòng không tìm được span: 0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, valid_df = train_test_split(\n",
        "    train_df,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=train_df[\"sentiment\"]\n",
        ")\n",
        "\n",
        "print(\"Train:\", train_df.shape, \"Valid:\", valid_df.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:15.124176Z",
          "iopub.execute_input": "2025-11-20T14:14:15.124464Z",
          "iopub.status.idle": "2025-11-20T14:14:15.157517Z",
          "shell.execute_reply.started": "2025-11-20T14:14:15.124430Z",
          "shell.execute_reply": "2025-11-20T14:14:15.156762Z"
        },
        "id": "GD6znE0VrANz",
        "outputId": "60edd014-7b8b-4677-e89c-6b608ff1bd62"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Train: (24732, 8) Valid: (2749, 8)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:17.649510Z",
          "iopub.execute_input": "2025-11-20T14:14:17.650107Z",
          "iopub.status.idle": "2025-11-20T14:14:17.658639Z",
          "shell.execute_reply.started": "2025-11-20T14:14:17.650083Z",
          "shell.execute_reply": "2025-11-20T14:14:17.657998Z"
        },
        "id": "BIKJgwgcrAN0",
        "outputId": "08e5278d-a884-40eb-9591-f7050b2d0aaf"
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           textID                                               text  \\\n10907  817350a9a1  Tried Nokia`s Ovi music store: 'Nokia Music do...   \n20107  b2776c2690  I just filled out the forms to stop contributi...   \n23504  85dcce2756  is thinking what song to use for the next chil...   \n22630  e75353b6d2  in the words of liana corber: Moreover, WIAIH ...   \n17351  a86aefc3c2  Your second episode of Sonny WAC was on in New...   \n\n                                           selected_text sentiment  text_len  \\\n10907  Tried Nokia`s Ovi music store: 'Nokia Music do...   neutral       135   \n20107  I just filled out the forms to stop contributi...   neutral       137   \n23504  is thinking what song to use for the next chil...   neutral        64   \n22630                                             decent  positive       108   \n17351                                           AMAZING!  positive       106   \n\n       sel_len  char_start  char_end  \n10907      135           0       135  \n20107      137           0       137  \n23504       64           0        64  \n22630        6          96       102  \n17351        8          89        97  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>text_len</th>\n      <th>sel_len</th>\n      <th>char_start</th>\n      <th>char_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10907</th>\n      <td>817350a9a1</td>\n      <td>Tried Nokia`s Ovi music store: 'Nokia Music do...</td>\n      <td>Tried Nokia`s Ovi music store: 'Nokia Music do...</td>\n      <td>neutral</td>\n      <td>135</td>\n      <td>135</td>\n      <td>0</td>\n      <td>135</td>\n    </tr>\n    <tr>\n      <th>20107</th>\n      <td>b2776c2690</td>\n      <td>I just filled out the forms to stop contributi...</td>\n      <td>I just filled out the forms to stop contributi...</td>\n      <td>neutral</td>\n      <td>137</td>\n      <td>137</td>\n      <td>0</td>\n      <td>137</td>\n    </tr>\n    <tr>\n      <th>23504</th>\n      <td>85dcce2756</td>\n      <td>is thinking what song to use for the next chil...</td>\n      <td>is thinking what song to use for the next chil...</td>\n      <td>neutral</td>\n      <td>64</td>\n      <td>64</td>\n      <td>0</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>22630</th>\n      <td>e75353b6d2</td>\n      <td>in the words of liana corber: Moreover, WIAIH ...</td>\n      <td>decent</td>\n      <td>positive</td>\n      <td>108</td>\n      <td>6</td>\n      <td>96</td>\n      <td>102</td>\n    </tr>\n    <tr>\n      <th>17351</th>\n      <td>a86aefc3c2</td>\n      <td>Your second episode of Sonny WAC was on in New...</td>\n      <td>AMAZING!</td>\n      <td>positive</td>\n      <td>106</td>\n      <td>8</td>\n      <td>89</td>\n      <td>97</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:19.665634Z",
          "iopub.execute_input": "2025-11-20T14:14:19.666185Z",
          "iopub.status.idle": "2025-11-20T14:14:27.960473Z",
          "shell.execute_reply.started": "2025-11-20T14:14:19.666162Z",
          "shell.execute_reply": "2025-11-20T14:14:27.959920Z"
        },
        "colab": {
          "referenced_widgets": [
            "83174f38af504f9c968b124e3dc77fd2",
            "09d461c953ed4807a26eddcf1e048e98",
            "b24fd776953f4cccbf3080a97a253096",
            "0efb26e06cdb41f0b144439d45d983bf",
            "3cfb3cf4d60f4988be1981a32cb096d8"
          ]
        },
        "id": "yguvj_lRrAN0",
        "outputId": "4722ace4-0ecc-4400-a067-235477386837"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83174f38af504f9c968b124e3dc77fd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09d461c953ed4807a26eddcf1e048e98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b24fd776953f4cccbf3080a97a253096"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0efb26e06cdb41f0b144439d45d983bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cfb3cf4d60f4988be1981a32cb096d8"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def char_to_token_span(text, char_start, char_end, tokenizer, sentiment):\n",
        "    encoded = tokenizer(\n",
        "        sentiment,\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    offsets = encoded[\"offset_mapping\"]\n",
        "    seq_ids = encoded.sequence_ids()\n",
        "\n",
        "    token_start = None\n",
        "    token_end = None\n",
        "\n",
        "    for i, (s, e) in enumerate(offsets):\n",
        "        if seq_ids[i] != 1:\n",
        "            continue\n",
        "        if s is None or e is None:\n",
        "            continue\n",
        "        if s <= char_start < e:\n",
        "            token_start = i\n",
        "        if s < char_end <= e:\n",
        "            token_end = i\n",
        "\n",
        "    return encoded, token_start, token_end\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:35.549013Z",
          "iopub.execute_input": "2025-11-20T14:14:35.549872Z",
          "iopub.status.idle": "2025-11-20T14:14:35.554616Z",
          "shell.execute_reply.started": "2025-11-20T14:14:35.549848Z",
          "shell.execute_reply": "2025-11-20T14:14:35.553864Z"
        },
        "id": "wjlSqG3LrAN1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def add_token_spans(df):\n",
        "    token_starts = []\n",
        "    token_ends = []\n",
        "    input_encodings = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        text = row[\"text\"]\n",
        "        sent = row[\"sentiment\"]\n",
        "        cs = row[\"char_start\"]\n",
        "        ce = row[\"char_end\"]\n",
        "\n",
        "        encoded, ts, te = char_to_token_span(text, cs, ce, tokenizer, sent)\n",
        "\n",
        "        token_starts.append(ts)\n",
        "        token_ends.append(te)\n",
        "        input_encodings.append(encoded)\n",
        "\n",
        "    df[\"token_start\"] = token_starts\n",
        "    df[\"token_end\"] = token_ends\n",
        "    df[\"encoded\"] = input_encodings\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:37.824130Z",
          "iopub.execute_input": "2025-11-20T14:14:37.824747Z",
          "iopub.status.idle": "2025-11-20T14:14:37.830348Z",
          "shell.execute_reply.started": "2025-11-20T14:14:37.824694Z",
          "shell.execute_reply": "2025-11-20T14:14:37.829365Z"
        },
        "id": "yF3iEKiRrAN2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = add_token_spans(train_df)\n",
        "valid_df = add_token_spans(valid_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:14:40.264222Z",
          "iopub.execute_input": "2025-11-20T14:14:40.264959Z",
          "iopub.status.idle": "2025-11-20T14:14:48.935375Z",
          "shell.execute_reply.started": "2025-11-20T14:14:40.264934Z",
          "shell.execute_reply": "2025-11-20T14:14:48.934639Z"
        },
        "id": "y-BPOE-TrAN2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[[\"text\", \"selected_text\", \"token_start\", \"token_end\"]].head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:20.776818Z",
          "iopub.execute_input": "2025-11-20T14:15:20.777564Z",
          "iopub.status.idle": "2025-11-20T14:15:20.789256Z",
          "shell.execute_reply.started": "2025-11-20T14:15:20.777542Z",
          "shell.execute_reply": "2025-11-20T14:15:20.788446Z"
        },
        "id": "l7zCiQ9PrAN2",
        "outputId": "e6b4bf33-dfc6-434e-c4fd-dde498bfcb96"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                    text  \\\n10907  Tried Nokia`s Ovi music store: 'Nokia Music do...   \n20107  I just filled out the forms to stop contributi...   \n23504  is thinking what song to use for the next chil...   \n22630  in the words of liana corber: Moreover, WIAIH ...   \n17351  Your second episode of Sonny WAC was on in New...   \n\n                                           selected_text  token_start  \\\n10907  Tried Nokia`s Ovi music store: 'Nokia Music do...            4   \n20107  I just filled out the forms to stop contributi...            4   \n23504  is thinking what song to use for the next chil...            4   \n22630                                             decent           29   \n17351                                           AMAZING!           25   \n\n       token_end  \n10907         35  \n20107         31  \n23504         16  \n22630         29  \n17351         28  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>token_start</th>\n      <th>token_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10907</th>\n      <td>Tried Nokia`s Ovi music store: 'Nokia Music do...</td>\n      <td>Tried Nokia`s Ovi music store: 'Nokia Music do...</td>\n      <td>4</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>20107</th>\n      <td>I just filled out the forms to stop contributi...</td>\n      <td>I just filled out the forms to stop contributi...</td>\n      <td>4</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>23504</th>\n      <td>is thinking what song to use for the next chil...</td>\n      <td>is thinking what song to use for the next chil...</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>22630</th>\n      <td>in the words of liana corber: Moreover, WIAIH ...</td>\n      <td>decent</td>\n      <td>29</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>17351</th>\n      <td>Your second episode of Sonny WAC was on in New...</td>\n      <td>AMAZING!</td>\n      <td>25</td>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"None token_start train:\", sum(t is None for t in train_df[\"token_start\"]))\n",
        "print(\"None token_end train:\", sum(t is None for t in train_df[\"token_end\"]))\n",
        "\n",
        "print(\"None token_start valid:\", sum(t is None for t in valid_df[\"token_start\"]))\n",
        "print(\"None token_end valid:\", sum(t is None for t in valid_df[\"token_end\"]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:23.812344Z",
          "iopub.execute_input": "2025-11-20T14:15:23.812633Z",
          "iopub.status.idle": "2025-11-20T14:15:23.823965Z",
          "shell.execute_reply.started": "2025-11-20T14:15:23.812612Z",
          "shell.execute_reply": "2025-11-20T14:15:23.823306Z"
        },
        "id": "4P4M4gFwrAN3",
        "outputId": "cf86d5b2-a5e0-483b-b7fb-6c81093e10ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "None token_start train: 0\nNone token_end train: 0\nNone token_start valid: 0\nNone token_end valid: 0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.encodings = df[\"encoded\"].tolist()\n",
        "        self.starts = df[\"token_start\"].tolist()\n",
        "        self.ends = df[\"token_end\"].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.encodings[idx]\n",
        "        start = self.starts[idx]\n",
        "        end = self.ends[idx]\n",
        "\n",
        "        encoding = {\n",
        "            \"input_ids\": torch.tensor(item[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(item[\"attention_mask\"], dtype=torch.long),\n",
        "            # RoBERTa không cần token_type_ids\n",
        "            \"start_positions\": torch.tensor(start, dtype=torch.long),\n",
        "            \"end_positions\": torch.tensor(end, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "        return encoding"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:25.894236Z",
          "iopub.execute_input": "2025-11-20T14:15:25.894966Z",
          "iopub.status.idle": "2025-11-20T14:15:25.900429Z",
          "shell.execute_reply.started": "2025-11-20T14:15:25.894940Z",
          "shell.execute_reply": "2025-11-20T14:15:25.899705Z"
        },
        "id": "Si9J5fQArAN3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TweetDataset(train_df)\n",
        "valid_dataset = TweetDataset(valid_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:28.696054Z",
          "iopub.execute_input": "2025-11-20T14:15:28.696812Z",
          "iopub.status.idle": "2025-11-20T14:15:28.702646Z",
          "shell.execute_reply.started": "2025-11-20T14:15:28.696778Z",
          "shell.execute_reply": "2025-11-20T14:15:28.701945Z"
        },
        "id": "lpU6Q3r9rAN3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(valid_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:30.840015Z",
          "iopub.execute_input": "2025-11-20T14:15:30.840630Z",
          "iopub.status.idle": "2025-11-20T14:15:30.845741Z",
          "shell.execute_reply.started": "2025-11-20T14:15:30.840608Z",
          "shell.execute_reply": "2025-11-20T14:15:30.845162Z"
        },
        "id": "YXY04qWorAN3",
        "outputId": "daef4dba-5236-41b7-9478-72168c5cb6be"
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(24732, 2749)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:34.092210Z",
          "iopub.execute_input": "2025-11-20T14:15:34.092471Z",
          "iopub.status.idle": "2025-11-20T14:15:34.096586Z",
          "shell.execute_reply.started": "2025-11-20T14:15:34.092451Z",
          "shell.execute_reply": "2025-11-20T14:15:34.095880Z"
        },
        "id": "xwVV-JcLrAN4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "for k,v in batch.items():\n",
        "    print(k, v.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:36.508172Z",
          "iopub.execute_input": "2025-11-20T14:15:36.508797Z",
          "iopub.status.idle": "2025-11-20T14:15:36.533139Z",
          "shell.execute_reply.started": "2025-11-20T14:15:36.508764Z",
          "shell.execute_reply": "2025-11-20T14:15:36.532454Z"
        },
        "id": "nF_stTBUrAN4",
        "outputId": "67dd39fb-e429-493e-95b3-017523d4ce7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "input_ids torch.Size([16, 128])\nattention_mask torch.Size([16, 128])\nstart_positions torch.Size([16])\nend_positions torch.Size([16])\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "class RobertaSpanModel(nn.Module):\n",
        "    def __init__(self, model_name=\"roberta-base\"):\n",
        "        super().__init__()\n",
        "        self.roberta = AutoModel.from_pretrained(model_name)\n",
        "        hidden = self.roberta.config.hidden_size\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.start_classifier = nn.Linear(hidden, 1)\n",
        "        self.end_classifier = nn.Linear(hidden, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.roberta(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        start_logits = self.start_classifier(sequence_output).squeeze(-1)\n",
        "        end_logits = self.end_classifier(sequence_output).squeeze(-1)\n",
        "\n",
        "        return start_logits, end_logits"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:39.941024Z",
          "iopub.execute_input": "2025-11-20T14:15:39.941657Z",
          "iopub.status.idle": "2025-11-20T14:15:39.971416Z",
          "shell.execute_reply.started": "2025-11-20T14:15:39.941630Z",
          "shell.execute_reply": "2025-11-20T14:15:39.970905Z"
        },
        "id": "O6l_mIlYrAN4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard(str1, str2):\n",
        "    a = set(str1.lower().split())\n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c) + 1e-15)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:42.680192Z",
          "iopub.execute_input": "2025-11-20T14:15:42.680757Z",
          "iopub.status.idle": "2025-11-20T14:15:42.684866Z",
          "shell.execute_reply.started": "2025-11-20T14:15:42.680697Z",
          "shell.execute_reply": "2025-11-20T14:15:42.684236Z"
        },
        "id": "2LKAvtd4rAN4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_span(text, start_idx, end_idx, offsets):\n",
        "    if start_idx is None or end_idx is None:\n",
        "        return text  # fallback\n",
        "\n",
        "    start_char = offsets[start_idx][0]\n",
        "    end_char = offsets[end_idx][1]\n",
        "    return text[start_char:end_char]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:44.668569Z",
          "iopub.execute_input": "2025-11-20T14:15:44.669186Z",
          "iopub.status.idle": "2025-11-20T14:15:44.673095Z",
          "shell.execute_reply.started": "2025-11-20T14:15:44.669163Z",
          "shell.execute_reply": "2025-11-20T14:15:44.672393Z"
        },
        "id": "kLo1Bj-lrAN5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, loader, df):\n",
        "    model.eval()\n",
        "    scores = []\n",
        "    sample_idx = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            start_logits, end_logits = model(input_ids, attention_mask)\n",
        "            pred_start = start_logits.argmax(dim=1).cpu().numpy()\n",
        "            pred_end = end_logits.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            for i in range(len(pred_start)):\n",
        "                row = df.iloc[sample_idx]\n",
        "                text = row.text\n",
        "                offsets = row.encoded[\"offset_mapping\"]\n",
        "\n",
        "                # Safety checks\n",
        "                if pred_end[i] < pred_start[i]:\n",
        "                    pred_end[i] = pred_start[i]\n",
        "\n",
        "                if pred_start[i] >= len(offsets) or pred_end[i] >= len(offsets):\n",
        "                    pred_text = text\n",
        "                else:\n",
        "                    pred_text = decode_span(\n",
        "                        text,\n",
        "                        pred_start[i],\n",
        "                        pred_end[i],\n",
        "                        offsets\n",
        "                    )\n",
        "\n",
        "                # Neutral rule\n",
        "                if row.sentiment == \"neutral\":\n",
        "                    pred_text = text\n",
        "\n",
        "                score = jaccard(row.selected_text, pred_text)\n",
        "                scores.append(score)\n",
        "\n",
        "                sample_idx += 1\n",
        "\n",
        "    return sum(scores) / len(scores)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:49.024351Z",
          "iopub.execute_input": "2025-11-20T14:15:49.024927Z",
          "iopub.status.idle": "2025-11-20T14:15:49.031038Z",
          "shell.execute_reply.started": "2025-11-20T14:15:49.024905Z",
          "shell.execute_reply": "2025-11-20T14:15:49.030268Z"
        },
        "id": "04i2YgdCrAN5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df[['text','selected_text','char_start','char_end','token_start','token_end']].sample(5))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T14:15:52.180412Z",
          "iopub.execute_input": "2025-11-20T14:15:52.180969Z",
          "iopub.status.idle": "2025-11-20T14:15:52.191333Z",
          "shell.execute_reply.started": "2025-11-20T14:15:52.180944Z",
          "shell.execute_reply": "2025-11-20T14:15:52.190756Z"
        },
        "id": "mTZSvIxgrAN5",
        "outputId": "13f3848d-dc41-44ba-f699-a242299f7dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                                                    text selected_text  \\\n26645                                         follow me!    follow me!   \n1314   you could say that. I left it in VT and have b...      I`m lost   \n21477  well I hovered over the button LOL NOT - sleep...       welcome   \n2602   I know! I`m so slow its horrible. DON`T TELL O...     horrible.   \n13854  i know.. i suck.. i`m a master procrastinator ...       i suck.   \n\n       char_start  char_end  token_start  token_end  \n26645           0        10            4          6  \n1314           86        94           24         27  \n21477          69        76           20         20  \n2602           24        33           13         14  \n13854           9        16            7          9  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaSpanModel().to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1*num_training_steps),\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T09:18:52.554200Z",
          "iopub.execute_input": "2025-11-20T09:18:52.554484Z",
          "iopub.status.idle": "2025-11-20T09:19:24.487086Z",
          "shell.execute_reply.started": "2025-11-20T09:18:52.554463Z",
          "shell.execute_reply": "2025-11-20T09:19:24.486323Z"
        },
        "id": "FQtX7mV4rAN6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss(ignore_index=-1, label_smoothing=0.1)\n",
        "\n",
        "best_jaccard = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    print(f\"\\n===== START EPOCH {epoch+1} =====\")\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        start_pos = batch[\"start_positions\"].to(device)\n",
        "        end_pos = batch[\"end_positions\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        start_logits, end_logits = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(start_logits, start_pos) + loss_fn(end_logits, end_pos)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # DEBUG PRINT EVERY 100 BATCHES\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1} | Step {step}/{len(train_loader)} | Loss: {loss.item():.4f}\", flush=True)\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - AVG Loss: {avg_loss:.4f}\", flush=True)\n",
        "\n",
        "    # VALIDATION\n",
        "    val_jaccard = validate(model, valid_loader, valid_df)\n",
        "    print(f\"Validation Jaccard: {val_jaccard:.4f}\", flush=True)\n",
        "    if val_jaccard > best_jaccard:\n",
        "        best_jaccard = val_jaccard\n",
        "        torch.save(model.state_dict(), \"best_roberta_span.pt\")\n",
        "        print(\"New BEST model saved:\", best_jaccard)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T09:19:46.504596Z",
          "iopub.execute_input": "2025-11-20T09:19:46.505199Z",
          "iopub.status.idle": "2025-11-20T09:49:47.871507Z",
          "shell.execute_reply.started": "2025-11-20T09:19:46.505176Z",
          "shell.execute_reply": "2025-11-20T09:49:47.870661Z"
        },
        "id": "0qbgGFfqWfN4",
        "outputId": "24da76ed-6a10-4d9d-883e-d105e9548891"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n===== START EPOCH 1 =====\nEpoch 1 | Step 0/1546 | Loss: 9.6679\nEpoch 1 | Step 100/1546 | Loss: 6.0124\nEpoch 1 | Step 200/1546 | Loss: 4.9506\nEpoch 1 | Step 300/1546 | Loss: 4.1618\nEpoch 1 | Step 400/1546 | Loss: 4.2348\nEpoch 1 | Step 500/1546 | Loss: 2.9897\nEpoch 1 | Step 600/1546 | Loss: 3.5676\nEpoch 1 | Step 700/1546 | Loss: 3.2887\nEpoch 1 | Step 800/1546 | Loss: 3.7730\nEpoch 1 | Step 900/1546 | Loss: 2.7415\nEpoch 1 | Step 1000/1546 | Loss: 2.5772\nEpoch 1 | Step 1100/1546 | Loss: 2.8053\nEpoch 1 | Step 1200/1546 | Loss: 3.0237\nEpoch 1 | Step 1300/1546 | Loss: 3.3996\nEpoch 1 | Step 1400/1546 | Loss: 3.0375\nEpoch 1 | Step 1500/1546 | Loss: 2.5656\nEpoch 1/3 - AVG Loss: 3.8074\nValidation Jaccard: 0.6931\nNew BEST model saved: 0.6930893112116753\n\n===== START EPOCH 2 =====\nEpoch 2 | Step 0/1546 | Loss: 3.3994\nEpoch 2 | Step 100/1546 | Loss: 3.5494\nEpoch 2 | Step 200/1546 | Loss: 3.6196\nEpoch 2 | Step 300/1546 | Loss: 3.2670\nEpoch 2 | Step 400/1546 | Loss: 2.9867\nEpoch 2 | Step 500/1546 | Loss: 3.3757\nEpoch 2 | Step 600/1546 | Loss: 2.6360\nEpoch 2 | Step 700/1546 | Loss: 3.8854\nEpoch 2 | Step 800/1546 | Loss: 2.8112\nEpoch 2 | Step 900/1546 | Loss: 2.9758\nEpoch 2 | Step 1000/1546 | Loss: 3.0628\nEpoch 2 | Step 1100/1546 | Loss: 3.0626\nEpoch 2 | Step 1200/1546 | Loss: 2.6761\nEpoch 2 | Step 1300/1546 | Loss: 2.6587\nEpoch 2 | Step 1400/1546 | Loss: 2.4760\nEpoch 2 | Step 1500/1546 | Loss: 2.4389\nEpoch 2/3 - AVG Loss: 3.1345\nValidation Jaccard: 0.7051\nNew BEST model saved: 0.7051076379457908\n\n===== START EPOCH 3 =====\nEpoch 3 | Step 0/1546 | Loss: 3.6178\nEpoch 3 | Step 100/1546 | Loss: 2.5850\nEpoch 3 | Step 200/1546 | Loss: 2.5067\nEpoch 3 | Step 300/1546 | Loss: 2.7117\nEpoch 3 | Step 400/1546 | Loss: 3.8267\nEpoch 3 | Step 500/1546 | Loss: 2.3769\nEpoch 3 | Step 600/1546 | Loss: 2.8056\nEpoch 3 | Step 700/1546 | Loss: 2.8903\nEpoch 3 | Step 800/1546 | Loss: 3.3753\nEpoch 3 | Step 900/1546 | Loss: 3.6656\nEpoch 3 | Step 1000/1546 | Loss: 3.1416\nEpoch 3 | Step 1100/1546 | Loss: 2.6896\nEpoch 3 | Step 1200/1546 | Loss: 3.0730\nEpoch 3 | Step 1300/1546 | Loss: 2.9528\nEpoch 3 | Step 1400/1546 | Loss: 3.7419\nEpoch 3 | Step 1500/1546 | Loss: 3.1734\nEpoch 3/3 - AVG Loss: 2.9463\nValidation Jaccard: 0.7059\nNew BEST model saved: 0.7059076568652524\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaSpanModel().to(device)\n",
        "model.load_state_dict(torch.load(\"/kaggle/working/best_roberta_span.pt\", map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T09:51:04.041179Z",
          "iopub.execute_input": "2025-11-20T09:51:04.041716Z",
          "iopub.status.idle": "2025-11-20T09:51:04.996423Z",
          "shell.execute_reply.started": "2025-11-20T09:51:04.041691Z",
          "shell.execute_reply": "2025-11-20T09:51:04.995370Z"
        },
        "id": "g4sfCm26rAN7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_span(text, start_idx, end_idx, offsets):\n",
        "    if start_idx is None or end_idx is None:\n",
        "        return text\n",
        "    start_char = offsets[start_idx][0]\n",
        "    end_char = offsets[end_idx][1]\n",
        "    return text[start_char:end_char]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T09:51:19.188100Z",
          "iopub.execute_input": "2025-11-20T09:51:19.188377Z",
          "iopub.status.idle": "2025-11-20T09:51:19.192364Z",
          "shell.execute_reply.started": "2025-11-20T09:51:19.188357Z",
          "shell.execute_reply": "2025-11-20T09:51:19.191710Z"
        },
        "id": "R2kWyxL3rAN7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(10):\n",
        "    sample = test_df.iloc[idx]\n",
        "\n",
        "    text = sample.text\n",
        "    sent = sample.sentiment\n",
        "\n",
        "    enc = tokenizer(\n",
        "        sent,\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    input_ids = torch.tensor([enc[\"input_ids\"]]).to(device)\n",
        "    attn = torch.tensor([enc[\"attention_mask\"]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start_logits, end_logits = model(input_ids, attn)\n",
        "\n",
        "    ps = start_logits.argmax(-1).item()\n",
        "    pe = end_logits.argmax(-1).item()\n",
        "\n",
        "    pred = decode_span(text, ps, pe, enc[\"offset_mapping\"])\n",
        "\n",
        "    print(\"========== SAMPLE\", idx, \"==========\")\n",
        "    print(\"Sentiment:\", sent)\n",
        "    print(\"TEXT:\", text)\n",
        "    print(\"PRED:\", pred)\n",
        "    print()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-20T08:17:18.247310Z",
          "iopub.execute_input": "2025-11-20T08:17:18.248060Z",
          "iopub.status.idle": "2025-11-20T08:17:18.415608Z",
          "shell.execute_reply.started": "2025-11-20T08:17:18.248032Z",
          "shell.execute_reply": "2025-11-20T08:17:18.414775Z"
        },
        "id": "5avaBck1WfN6",
        "outputId": "9780c755-6a02-4cc9-c44e-8ec8025174dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "========== SAMPLE 0 ==========\nSentiment: neutral\nTEXT: Last session of the day http://twitpic.com/67ezh\nPRED: Last session of the day\n\n========== SAMPLE 1 ==========\nSentiment: positive\nTEXT: Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China: (SH) (BJ).\nPRED: exciting\n\n========== SAMPLE 2 ==========\nSentiment: negative\nTEXT: Recession hit Veronique Branquinho, she has to quit her company, such a shame!\nPRED: such a shame!\n\n========== SAMPLE 3 ==========\nSentiment: positive\nTEXT: happy bday!\nPRED: happy\n\n========== SAMPLE 4 ==========\nSentiment: positive\nTEXT: http://twitpic.com/4w75p - I like it!!\nPRED: I like\n\n========== SAMPLE 5 ==========\nSentiment: positive\nTEXT: that`s great!! weee!! visitors!\nPRED: that`s great!!\n\n========== SAMPLE 6 ==========\nSentiment: negative\nTEXT: I THINK EVERYONE HATES ME ON HERE lol\nPRED: HATES\n\n========== SAMPLE 7 ==========\nSentiment: negative\nTEXT: soooooo wish i could, but im in school and myspace is completely blocked\nPRED: blocked\n\n========== SAMPLE 8 ==========\nSentiment: neutral\nTEXT: and within a short time of the last clue all of them\nPRED: and within a short time of the last clue all of them\n\n========== SAMPLE 9 ==========\nSentiment: neutral\nTEXT: What did you get? My day is alright.. haven`t done anything yet. leaving soon to my stepsister though!\nPRED: What did you get? My day is alright.. haven`t done anything yet. leaving soon to my stepsister though!\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "j7v23W_4t_2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "DATA_PATH = \"/kaggle/input/tweet-sentiment-extraction\"\n",
        "\n",
        "train_df = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
        "test_df  = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
        "print(train_df.shape, test_df.shape)\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T04:39:58.778456Z",
          "iopub.execute_input": "2025-11-21T04:39:58.779006Z",
          "iopub.status.idle": "2025-11-21T04:39:59.767568Z",
          "shell.execute_reply.started": "2025-11-21T04:39:58.778982Z",
          "shell.execute_reply": "2025-11-21T04:39:59.766961Z"
        },
        "id": "QTHfumYdrAN_",
        "outputId": "b15746cd-d4e1-4fe7-c47c-bc1c348b0e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "(27481, 4) (3534, 3)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment  \n0  I`d have responded, if I were going   neutral  \n1                             Sooo SAD  negative  \n2                          bullying me  negative  \n3                       leave me alone  negative  \n4                        Sons of ****,  negative  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def clean_text_safe(s):\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = s.strip()\n",
        "    return s\n",
        "\n",
        "\n",
        "train_df[\"text\"] = train_df[\"text\"].astype(str).apply(clean_text_safe)\n",
        "train_df[\"selected_text\"] = train_df[\"selected_text\"].astype(str).apply(clean_text_safe)\n",
        "test_df[\"text\"] = test_df[\"text\"].astype(str).apply(clean_text_safe)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T04:40:02.640026Z",
          "iopub.execute_input": "2025-11-21T04:40:02.640310Z",
          "iopub.status.idle": "2025-11-21T04:40:02.672951Z",
          "shell.execute_reply.started": "2025-11-21T04:40:02.640290Z",
          "shell.execute_reply": "2025-11-21T04:40:02.672277Z"
        },
        "id": "8MzmV77ErAN_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"text_len\"] = train_df[\"text\"].str.len()\n",
        "train_df[\"sel_len\"] = train_df[\"selected_text\"].str.len()\n",
        "train_df[[\"text\", \"selected_text\", \"text_len\", \"sel_len\"]].head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T04:40:06.070368Z",
          "iopub.execute_input": "2025-11-21T04:40:06.070642Z",
          "iopub.status.idle": "2025-11-21T04:40:06.107931Z",
          "shell.execute_reply.started": "2025-11-21T04:40:06.070622Z",
          "shell.execute_reply": "2025-11-21T04:40:06.107217Z"
        },
        "id": "CJSksL4KrAOA",
        "outputId": "693ef117-622b-4fc6-d8f8-167b9541486d"
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                text  \\\n0                I`d have responded, if I were going   \n1      Sooo SAD I will miss you here in San Diego!!!   \n2                          my boss is bullying me...   \n3                     what interview! leave me alone   \n4  Sons of ****, why couldn`t they put them on th...   \n\n                         selected_text  text_len  sel_len  \n0  I`d have responded, if I were going        35       35  \n1                             Sooo SAD        45        8  \n2                          bullying me        25       11  \n3                       leave me alone        30       14  \n4                        Sons of ****,        74       13  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>text_len</th>\n      <th>sel_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>35</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>45</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>25</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>30</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on th...</td>\n      <td>Sons of ****,</td>\n      <td>74</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def find_selected_span_robust(row):\n",
        "    text = row[\"text\"]\n",
        "    selected = row[\"selected_text\"]\n",
        "\n",
        "    if text == selected:\n",
        "        return 0, len(text)\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    selected_lower = selected.lower().strip()\n",
        "\n",
        "    # 1. Tìm trực tiếp\n",
        "    idx = text_lower.find(selected_lower)\n",
        "    if idx != -1:\n",
        "        return idx, idx + len(selected_lower)\n",
        "\n",
        "    # 2. Thử remove double space trong text\n",
        "    text2 = re.sub(r\"\\s+\", \" \", text_lower)\n",
        "    idx = text2.find(selected_lower)\n",
        "    if idx != -1:\n",
        "        real_idx = text_lower.find(selected_lower[:5])\n",
        "        if real_idx != -1:\n",
        "            return real_idx, real_idx + len(selected)\n",
        "\n",
        "    # 3. Matching sliding window theo token (fallback)\n",
        "    best_score = 0\n",
        "    best_span = (0, 0)\n",
        "    for i in range(len(text_lower)):\n",
        "        for j in range(i+1, min(i+100, len(text_lower))):\n",
        "            substr = text_lower[i:j]\n",
        "            score = len(set(substr.split()) & set(selected_lower.split()))\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_span = (i, j)\n",
        "\n",
        "    if best_score > 0:\n",
        "        return best_span\n",
        "\n",
        "    return -1, -1\n",
        "\n",
        "\n",
        "span_indices = train_df.apply(find_selected_span_robust, axis=1)\n",
        "train_df[\"char_start\"] = span_indices.apply(lambda x: x[0])\n",
        "train_df[\"char_end\"] = span_indices.apply(lambda x: x[1])\n",
        "\n",
        "print(\"Số dòng không tìm được span:\", (train_df[\"char_start\"] == -1).sum())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T04:40:09.540736Z",
          "iopub.execute_input": "2025-11-21T04:40:09.541037Z",
          "iopub.status.idle": "2025-11-21T04:40:09.740791Z",
          "shell.execute_reply.started": "2025-11-21T04:40:09.541012Z",
          "shell.execute_reply": "2025-11-21T04:40:09.740186Z"
        },
        "id": "UALl_KTDrAOE",
        "outputId": "e456995e-ecc9-4feb-898f-362d08ab8a69"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Số dòng không tìm được span: 0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "full_df = train_df.copy()\n",
        "train_df = full_df\n",
        "\n",
        "print(\"Training data:\", train_df.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T04:40:13.779424Z",
          "iopub.execute_input": "2025-11-21T04:40:13.780060Z",
          "iopub.status.idle": "2025-11-21T04:40:13.789477Z",
          "shell.execute_reply.started": "2025-11-21T04:40:13.780036Z",
          "shell.execute_reply": "2025-11-21T04:40:13.788747Z"
        },
        "id": "jd9GkciArAOF",
        "outputId": "ca2957e3-adc2-4317-bf65-4bcd5147193c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training data: (27481, 8)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T04:40:16.271566Z",
          "iopub.execute_input": "2025-11-21T04:40:16.271832Z",
          "iopub.status.idle": "2025-11-21T04:40:16.280874Z",
          "shell.execute_reply.started": "2025-11-21T04:40:16.271813Z",
          "shell.execute_reply": "2025-11-21T04:40:16.280222Z"
        },
        "id": "eRZLEVG7rAOF",
        "outputId": "0247cb67-ce41-4e7a-a4f5-cd88704a041c"
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861  Sons of ****, why couldn`t they put them on th...   \n\n                         selected_text sentiment  text_len  sel_len  \\\n0  I`d have responded, if I were going   neutral        35       35   \n1                             Sooo SAD  negative        45        8   \n2                          bullying me  negative        25       11   \n3                       leave me alone  negative        30       14   \n4                        Sons of ****,  negative        74       13   \n\n   char_start  char_end  \n0           0        35  \n1           0         8  \n2          11        22  \n3          16        30  \n4           0        13  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>text_len</th>\n      <th>sel_len</th>\n      <th>char_start</th>\n      <th>char_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>35</td>\n      <td>35</td>\n      <td>0</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>45</td>\n      <td>8</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>25</td>\n      <td>11</td>\n      <td>11</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>30</td>\n      <td>14</td>\n      <td>16</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on th...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n      <td>74</td>\n      <td>13</td>\n      <td>0</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    row = train_df.iloc[i]\n",
        "    span = row.text[row.char_start:row.char_end]\n",
        "    print(\"TEXT:\", row.text)\n",
        "    print(\"SELECTED:\", row.selected_text)\n",
        "    print(\"SPAN:\", span)\n",
        "    print(\"-\"*40)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T04:40:19.081847Z",
          "iopub.execute_input": "2025-11-21T04:40:19.082198Z",
          "iopub.status.idle": "2025-11-21T04:40:19.088436Z",
          "shell.execute_reply.started": "2025-11-21T04:40:19.082176Z",
          "shell.execute_reply": "2025-11-21T04:40:19.087761Z"
        },
        "id": "Y1Zr3AgqrAOF",
        "outputId": "fd01f1be-4960-43e8-e12d-995b568c85b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "TEXT: I`d have responded, if I were going\nSELECTED: I`d have responded, if I were going\nSPAN: I`d have responded, if I were going\n----------------------------------------\nTEXT: Sooo SAD I will miss you here in San Diego!!!\nSELECTED: Sooo SAD\nSPAN: Sooo SAD\n----------------------------------------\nTEXT: my boss is bullying me...\nSELECTED: bullying me\nSPAN: bullying me\n----------------------------------------\nTEXT: what interview! leave me alone\nSELECTED: leave me alone\nSPAN: leave me alone\n----------------------------------------\nTEXT: Sons of ****, why couldn`t they put them on the releases we already bought\nSELECTED: Sons of ****,\nSPAN: Sons of ****,\n----------------------------------------\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T04:40:21.383742Z",
          "iopub.execute_input": "2025-11-21T04:40:21.384278Z",
          "iopub.status.idle": "2025-11-21T04:40:34.027320Z",
          "shell.execute_reply.started": "2025-11-21T04:40:21.384252Z",
          "shell.execute_reply": "2025-11-21T04:40:34.026583Z"
        },
        "colab": {
          "referenced_widgets": [
            "35ad4aec4c344ffa80c96961b271d3e1",
            "24038c9561b8490382dbc698d8a4eb1e",
            "c7ed5f56dfe14a6480c79f19197a003f",
            "8fcc4462152449c181b1c1aba4427693",
            "d0056b4b4ef4423bb926a514539ee195"
          ]
        },
        "id": "L9X46Z3QrAOG",
        "outputId": "6b7b660c-972f-4b1a-f7e5-528a59c80020"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35ad4aec4c344ffa80c96961b271d3e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24038c9561b8490382dbc698d8a4eb1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7ed5f56dfe14a6480c79f19197a003f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fcc4462152449c181b1c1aba4427693"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0056b4b4ef4423bb926a514539ee195"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def char_to_token_span(text, char_start, char_end, tokenizer, sentiment):\n",
        "    encoded = tokenizer(\n",
        "        sentiment,\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    offsets = encoded[\"offset_mapping\"]\n",
        "    seq_ids = encoded.sequence_ids()\n",
        "\n",
        "    token_start = None\n",
        "    token_end = None\n",
        "\n",
        "    for i, (s, e) in enumerate(offsets):\n",
        "        if seq_ids[i] != 1:\n",
        "            continue\n",
        "        if s is None or e is None:\n",
        "            continue\n",
        "        if s <= char_start < e:\n",
        "            token_start = i\n",
        "        if s < char_end <= e:\n",
        "            token_end = i\n",
        "\n",
        "    return encoded, token_start, token_end\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:13.068508Z",
          "iopub.execute_input": "2025-11-21T01:58:13.069181Z",
          "iopub.status.idle": "2025-11-21T01:58:13.074745Z",
          "shell.execute_reply.started": "2025-11-21T01:58:13.069155Z",
          "shell.execute_reply": "2025-11-21T01:58:13.073950Z"
        },
        "id": "fs0w0mD_rAOG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def add_token_spans(df):\n",
        "    token_starts = []\n",
        "    token_ends = []\n",
        "    input_encodings = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        text = row[\"text\"]\n",
        "        sent = row[\"sentiment\"]\n",
        "        cs = row[\"char_start\"]\n",
        "        ce = row[\"char_end\"]\n",
        "\n",
        "        encoded, ts, te = char_to_token_span(text, cs, ce, tokenizer, sent)\n",
        "\n",
        "        token_starts.append(ts)\n",
        "        token_ends.append(te)\n",
        "        input_encodings.append(encoded)\n",
        "\n",
        "    df[\"token_start\"] = token_starts\n",
        "    df[\"token_end\"] = token_ends\n",
        "    df[\"encoded\"] = input_encodings\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:16.279892Z",
          "iopub.execute_input": "2025-11-21T01:58:16.280185Z",
          "iopub.status.idle": "2025-11-21T01:58:16.285754Z",
          "shell.execute_reply.started": "2025-11-21T01:58:16.280163Z",
          "shell.execute_reply": "2025-11-21T01:58:16.284754Z"
        },
        "id": "wbAq-4nLrAOG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = add_token_spans(train_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:19.440201Z",
          "iopub.execute_input": "2025-11-21T01:58:19.440515Z",
          "iopub.status.idle": "2025-11-21T01:58:29.041569Z",
          "shell.execute_reply.started": "2025-11-21T01:58:19.440492Z",
          "shell.execute_reply": "2025-11-21T01:58:29.040798Z"
        },
        "id": "uAKCzwg5rAOH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[[\"text\", \"selected_text\", \"token_start\", \"token_end\"]].head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:31.743588Z",
          "iopub.execute_input": "2025-11-21T01:58:31.744441Z",
          "iopub.status.idle": "2025-11-21T01:58:31.755240Z",
          "shell.execute_reply.started": "2025-11-21T01:58:31.744407Z",
          "shell.execute_reply": "2025-11-21T01:58:31.754504Z"
        },
        "id": "2oCXrzidrAOH",
        "outputId": "7d689e85-4d79-45f7-df82-5796952bfcce"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                text  \\\n0                I`d have responded, if I were going   \n1      Sooo SAD I will miss you here in San Diego!!!   \n2                          my boss is bullying me...   \n3                     what interview! leave me alone   \n4  Sons of ****, why couldn`t they put them on th...   \n\n                         selected_text  token_start  token_end  \n0  I`d have responded, if I were going            4         13  \n1                             Sooo SAD            4          7  \n2                          bullying me            7          8  \n3                       leave me alone            7          9  \n4                        Sons of ****,            4          8  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>token_start</th>\n      <th>token_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>4</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>7</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sons of ****, why couldn`t they put them on th...</td>\n      <td>Sons of ****,</td>\n      <td>4</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"None token_start train:\", sum(t is None for t in train_df[\"token_start\"]))\n",
        "print(\"None token_end train:\", sum(t is None for t in train_df[\"token_end\"]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:34.075250Z",
          "iopub.execute_input": "2025-11-21T01:58:34.076000Z",
          "iopub.status.idle": "2025-11-21T01:58:34.092210Z",
          "shell.execute_reply.started": "2025-11-21T01:58:34.075966Z",
          "shell.execute_reply": "2025-11-21T01:58:34.091452Z"
        },
        "id": "5-0-QRhdrAOH",
        "outputId": "0432a3b9-d3f7-420e-f6d2-bdf89274c1d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "None token_start train: 0\nNone token_end train: 0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', 2)\n",
        "\n",
        "for idx, row in train_df.head(3).iterrows():\n",
        "    offsets = row[\"encoded\"][\"offset_mapping\"]\n",
        "    ts = row[\"token_start\"]\n",
        "    te = row[\"token_end\"]\n",
        "\n",
        "    if ts is None or te is None or ts == -1 or te == -1:\n",
        "        decoded = \"SPAN NOT FOUND\"\n",
        "    else:\n",
        "        start_char = offsets[ts][0]\n",
        "        end_char = offsets[te][1]\n",
        "        decoded = row.text[start_char:end_char]\n",
        "\n",
        "    print(f\"ROW INDEX: {idx}\")\n",
        "    print(\"TEXT:\", row.text)\n",
        "    print(\"SELECTED:\", row.selected_text)\n",
        "    print(\"DECODED FROM TOKENS:\", decoded)\n",
        "    print(\"-\"*60)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:36.690382Z",
          "iopub.execute_input": "2025-11-21T01:58:36.691190Z",
          "iopub.status.idle": "2025-11-21T01:58:36.700500Z",
          "shell.execute_reply.started": "2025-11-21T01:58:36.691156Z",
          "shell.execute_reply": "2025-11-21T01:58:36.699385Z"
        },
        "id": "Q-YSFVYwrAOH",
        "outputId": "3f279f0e-56df-4a3b-9d09-b7c8adfb5a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "ROW INDEX: 0\nTEXT: I`d have responded, if I were going\nSELECTED: I`d have responded, if I were going\nDECODED FROM TOKENS: I`d have responded, if I were going\n------------------------------------------------------------\nROW INDEX: 1\nTEXT: Sooo SAD I will miss you here in San Diego!!!\nSELECTED: Sooo SAD\nDECODED FROM TOKENS: Sooo SAD\n------------------------------------------------------------\nROW INDEX: 2\nTEXT: my boss is bullying me...\nSELECTED: bullying me\nDECODED FROM TOKENS: bullying me\n------------------------------------------------------------\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.encodings = df[\"encoded\"].tolist()\n",
        "        self.starts = df[\"token_start\"].tolist()\n",
        "        self.ends = df[\"token_end\"].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.encodings[idx]\n",
        "        start = self.starts[idx]\n",
        "        end = self.ends[idx]\n",
        "\n",
        "        encoding = {\n",
        "            \"input_ids\": torch.tensor(item[\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(item[\"attention_mask\"], dtype=torch.long),\n",
        "            # RoBERTa không cần token_type_ids\n",
        "            \"start_positions\": torch.tensor(start, dtype=torch.long),\n",
        "            \"end_positions\": torch.tensor(end, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "        return encoding"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:39.789265Z",
          "iopub.execute_input": "2025-11-21T01:58:39.789886Z",
          "iopub.status.idle": "2025-11-21T01:58:39.796105Z",
          "shell.execute_reply.started": "2025-11-21T01:58:39.789862Z",
          "shell.execute_reply": "2025-11-21T01:58:39.795205Z"
        },
        "id": "dZTv-iIorAOI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TweetDataset(train_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:42.750374Z",
          "iopub.execute_input": "2025-11-21T01:58:42.751114Z",
          "iopub.status.idle": "2025-11-21T01:58:42.759466Z",
          "shell.execute_reply.started": "2025-11-21T01:58:42.751080Z",
          "shell.execute_reply": "2025-11-21T01:58:42.758291Z"
        },
        "id": "avItDuVUrAOI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:45.121997Z",
          "iopub.execute_input": "2025-11-21T01:58:45.122348Z",
          "iopub.status.idle": "2025-11-21T01:58:45.128424Z",
          "shell.execute_reply.started": "2025-11-21T01:58:45.122324Z",
          "shell.execute_reply": "2025-11-21T01:58:45.127518Z"
        },
        "id": "cnJRnVvIrAOJ",
        "outputId": "cdf6209b-fa3e-4a89-a95f-354ee4655f6b"
      },
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "27481"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:47.346097Z",
          "iopub.execute_input": "2025-11-21T01:58:47.346412Z",
          "iopub.status.idle": "2025-11-21T01:58:47.351291Z",
          "shell.execute_reply.started": "2025-11-21T01:58:47.346389Z",
          "shell.execute_reply": "2025-11-21T01:58:47.350442Z"
        },
        "id": "GvzEdHfGrAOJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "for k,v in batch.items():\n",
        "    print(k, v.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:49.554299Z",
          "iopub.execute_input": "2025-11-21T01:58:49.554612Z",
          "iopub.status.idle": "2025-11-21T01:58:49.579325Z",
          "shell.execute_reply.started": "2025-11-21T01:58:49.554589Z",
          "shell.execute_reply": "2025-11-21T01:58:49.578530Z"
        },
        "id": "RFLceulqrAOJ",
        "outputId": "a7cbfb91-8d6b-492b-acc7-286884c1ea72"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "input_ids torch.Size([16, 128])\nattention_mask torch.Size([16, 128])\nstart_positions torch.Size([16])\nend_positions torch.Size([16])\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "class RobertaSpanModel(nn.Module):\n",
        "    def __init__(self, model_name=\"roberta-base\"):\n",
        "        super().__init__()\n",
        "        self.roberta = AutoModel.from_pretrained(model_name)\n",
        "        hidden = self.roberta.config.hidden_size\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.start_classifier = nn.Linear(hidden, 1)\n",
        "        self.end_classifier = nn.Linear(hidden, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.roberta(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
        "\n",
        "        start_logits = self.start_classifier(sequence_output).squeeze(-1)\n",
        "        end_logits = self.end_classifier(sequence_output).squeeze(-1)\n",
        "\n",
        "        return start_logits, end_logits"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:58:56.006567Z",
          "iopub.execute_input": "2025-11-21T01:58:56.007426Z",
          "iopub.status.idle": "2025-11-21T01:58:56.038748Z",
          "shell.execute_reply.started": "2025-11-21T01:58:56.007399Z",
          "shell.execute_reply": "2025-11-21T01:58:56.037883Z"
        },
        "id": "osBsuD5QrAOK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df[['text','selected_text','char_start','char_end','token_start','token_end']].sample(5))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:59:00.521581Z",
          "iopub.execute_input": "2025-11-21T01:59:00.522254Z",
          "iopub.status.idle": "2025-11-21T01:59:00.533345Z",
          "shell.execute_reply.started": "2025-11-21T01:59:00.522228Z",
          "shell.execute_reply": "2025-11-21T01:59:00.532465Z"
        },
        "id": "p3JAD1z4rAOL",
        "outputId": "9daa0a83-64d9-48e1-a1da-3ae9850ec9f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                                                                                                                 text  \\\n6467   Looks like rain again  Oh well, it will give me a chance to work on a new crochet pattern I have in the works.   \n19988  very familiar.....sorry you`re feeling that way                                                                  \n26182  so happy its friday...not so happy about this rain                                                               \n6830   Yes, sir!   See here http://is.gd/wz2K                                                                           \n25762  now i dont feel so good                                                                                          \n\n                 selected_text  char_start  char_end  token_start  token_end  \n6467   give me a chance         40          56        14           17         \n19988  .sorry                   17          23        6            7          \n26182  happy                    3           8         5            5          \n6830   Yes, sir!   See her      0           19        4            11         \n25762  now i dont feel so good  0           23        4            9          \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RobertaSpanModel().to(device)\n",
        "num_epochs = 3\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(0.1*num_training_steps),\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:59:03.566001Z",
          "iopub.execute_input": "2025-11-21T01:59:03.566376Z",
          "iopub.status.idle": "2025-11-21T01:59:35.420207Z",
          "shell.execute_reply.started": "2025-11-21T01:59:03.566349Z",
          "shell.execute_reply": "2025-11-21T01:59:35.419298Z"
        },
        "colab": {
          "referenced_widgets": [
            "7583786ac59c44d49f719136ca61761d"
          ]
        },
        "id": "2bH5Yg1XrAOL",
        "outputId": "a8455de5-4461-4456-80ae-f0ecf136a981"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-11-21 01:59:12.623080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763690352.857800      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763690352.920705      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7583786ac59c44d49f719136ca61761d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== SET SEED (ĐỔI SỐ MỖI LẦN TRAIN) ==================\n",
        "SEED = 42   # ĐỔI: 42 -> 123 -> 999 cho các lần train khác\n",
        "\n",
        "import random\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:59:40.666819Z",
          "iopub.execute_input": "2025-11-21T01:59:40.668065Z",
          "iopub.status.idle": "2025-11-21T01:59:40.679179Z",
          "shell.execute_reply.started": "2025-11-21T01:59:40.668026Z",
          "shell.execute_reply": "2025-11-21T01:59:40.678288Z"
        },
        "id": "Qv4lDyftrAOM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== MODEL + OPTIMIZER ==================\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "model.train()\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    print(f\"\\n===== EPOCH {epoch+1}/{num_epochs} =====\")\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        start_pos = batch[\"start_positions\"].to(device)\n",
        "        end_pos = batch[\"end_positions\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        start_logits, end_logits = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(start_logits, start_pos) + loss_fn(end_logits, end_pos)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch+1} | Step {step}/{len(train_loader)} \"\n",
        "                f\"| Loss: {loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} - AVG Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T01:59:48.871425Z",
          "iopub.execute_input": "2025-11-21T01:59:48.872238Z",
          "iopub.status.idle": "2025-11-21T02:35:49.591385Z",
          "shell.execute_reply.started": "2025-11-21T01:59:48.872208Z",
          "shell.execute_reply": "2025-11-21T02:35:49.590528Z"
        },
        "id": "N3Euhas2rAOM",
        "outputId": "ea6fcd58-8e0a-4512-b836-e48b35ac4c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n===== EPOCH 1/3 =====\nEpoch 1 | Step 0/1718 | Loss: 9.7491\nEpoch 1 | Step 100/1718 | Loss: 5.6244\nEpoch 1 | Step 200/1718 | Loss: 2.7836\nEpoch 1 | Step 300/1718 | Loss: 2.3207\nEpoch 1 | Step 400/1718 | Loss: 2.6585\nEpoch 1 | Step 500/1718 | Loss: 1.5905\nEpoch 1 | Step 600/1718 | Loss: 1.7285\nEpoch 1 | Step 700/1718 | Loss: 1.4214\nEpoch 1 | Step 800/1718 | Loss: 0.8427\nEpoch 1 | Step 900/1718 | Loss: 1.2676\nEpoch 1 | Step 1000/1718 | Loss: 2.1941\nEpoch 1 | Step 1100/1718 | Loss: 1.1719\nEpoch 1 | Step 1200/1718 | Loss: 1.8153\nEpoch 1 | Step 1300/1718 | Loss: 1.3222\nEpoch 1 | Step 1400/1718 | Loss: 1.4394\nEpoch 1 | Step 1500/1718 | Loss: 1.5815\nEpoch 1 | Step 1600/1718 | Loss: 1.5935\nEpoch 1 | Step 1700/1718 | Loss: 2.2523\nEpoch 1 - AVG Loss: 2.5133\n\n===== EPOCH 2/3 =====\nEpoch 2 | Step 0/1718 | Loss: 1.4007\nEpoch 2 | Step 100/1718 | Loss: 1.0816\nEpoch 2 | Step 200/1718 | Loss: 1.7137\nEpoch 2 | Step 300/1718 | Loss: 1.5622\nEpoch 2 | Step 400/1718 | Loss: 1.8800\nEpoch 2 | Step 500/1718 | Loss: 3.2014\nEpoch 2 | Step 600/1718 | Loss: 1.4657\nEpoch 2 | Step 700/1718 | Loss: 2.1384\nEpoch 2 | Step 800/1718 | Loss: 1.6466\nEpoch 2 | Step 900/1718 | Loss: 1.9554\nEpoch 2 | Step 1000/1718 | Loss: 2.9606\nEpoch 2 | Step 1100/1718 | Loss: 1.2066\nEpoch 2 | Step 1200/1718 | Loss: 1.0143\nEpoch 2 | Step 1300/1718 | Loss: 1.5160\nEpoch 2 | Step 1400/1718 | Loss: 1.4496\nEpoch 2 | Step 1500/1718 | Loss: 1.4060\nEpoch 2 | Step 1600/1718 | Loss: 3.4928\nEpoch 2 | Step 1700/1718 | Loss: 1.4719\nEpoch 2 - AVG Loss: 1.5475\n\n===== EPOCH 3/3 =====\nEpoch 3 | Step 0/1718 | Loss: 1.2562\nEpoch 3 | Step 100/1718 | Loss: 1.4601\nEpoch 3 | Step 200/1718 | Loss: 1.3584\nEpoch 3 | Step 300/1718 | Loss: 1.6859\nEpoch 3 | Step 400/1718 | Loss: 1.3652\nEpoch 3 | Step 500/1718 | Loss: 0.8918\nEpoch 3 | Step 600/1718 | Loss: 1.4885\nEpoch 3 | Step 700/1718 | Loss: 0.9805\nEpoch 3 | Step 800/1718 | Loss: 1.8961\nEpoch 3 | Step 900/1718 | Loss: 2.2077\nEpoch 3 | Step 1000/1718 | Loss: 1.4869\nEpoch 3 | Step 1100/1718 | Loss: 1.4266\nEpoch 3 | Step 1200/1718 | Loss: 1.3112\nEpoch 3 | Step 1300/1718 | Loss: 1.5506\nEpoch 3 | Step 1400/1718 | Loss: 1.3854\nEpoch 3 | Step 1500/1718 | Loss: 2.3258\nEpoch 3 | Step 1600/1718 | Loss: 1.0788\nEpoch 3 | Step 1700/1718 | Loss: 1.3012\nEpoch 3 - AVG Loss: 1.3597\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== SAVE MODEL ==================\n",
        "model_path = f\"robertaV2.pt\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"\\nMODEL SAVED: {model_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T02:47:55.777153Z",
          "iopub.execute_input": "2025-11-21T02:47:55.777875Z",
          "iopub.status.idle": "2025-11-21T02:47:56.619486Z",
          "shell.execute_reply.started": "2025-11-21T02:47:55.777853Z",
          "shell.execute_reply": "2025-11-21T02:47:56.618809Z"
        },
        "id": "w91WlWkdrAON",
        "outputId": "b2457b50-b002-4e5f-f50c-57f8a0a0ae19"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nMODEL SAVED: robertaV2.pt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaSpanModel().to(device)\n",
        "model.load_state_dict(torch.load(\"/kaggle/working/robertaV2.pt\", map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T02:48:46.081182Z",
          "iopub.execute_input": "2025-11-21T02:48:46.081688Z",
          "iopub.status.idle": "2025-11-21T02:48:46.856174Z",
          "shell.execute_reply.started": "2025-11-21T02:48:46.081665Z",
          "shell.execute_reply": "2025-11-21T02:48:46.855404Z"
        },
        "id": "K49qhoJ6rAON",
        "outputId": "931163a3-306c-4646-c87d-2059b2dbb9ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "RobertaSpanModel(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (start_classifier): Linear(in_features=768, out_features=1, bias=True)\n  (end_classifier): Linear(in_features=768, out_features=1, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble"
      ],
      "metadata": {
        "id": "ib_q_7nluK51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = RobertaSpanModel().to(device)\n",
        "model2 = RobertaSpanModel().to(device)\n",
        "\n",
        "model1.load_state_dict(torch.load(\"/kaggle/input/last-epoch-mode/last_epoch_model.pt\"))\n",
        "model2.load_state_dict(torch.load(\"/kaggle/input/robertav2/robertaV2.pt\"))\n",
        "\n",
        "model1.eval()\n",
        "model2.eval()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T07:12:55.288597Z",
          "iopub.execute_input": "2025-11-21T07:12:55.289347Z",
          "iopub.status.idle": "2025-11-21T07:12:56.796198Z",
          "shell.execute_reply.started": "2025-11-21T07:12:55.289324Z",
          "shell.execute_reply": "2025-11-21T07:12:56.795595Z"
        },
        "id": "N50Q_IGxrAOY",
        "outputId": "60f3ccda-7310-4581-b7ec-0b00af4fe6a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "RobertaSpanModel(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (start_classifier): Linear(in_features=768, out_features=1, bias=True)\n  (end_classifier): Linear(in_features=768, out_features=1, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_span(text, start_idx, end_idx, offsets):\n",
        "\n",
        "    if start_idx is None or end_idx is None:\n",
        "        return text\n",
        "    if start_idx < 0 or end_idx >= len(offsets):\n",
        "        return text\n",
        "    if end_idx < start_idx:\n",
        "        end_idx = start_idx\n",
        "\n",
        "    start_char = offsets[start_idx][0]\n",
        "    end_char = offsets[end_idx][1]\n",
        "\n",
        "    if start_char is None or end_char is None:\n",
        "        return text\n",
        "\n",
        "    pred = text[start_char:end_char]\n",
        "\n",
        "    # Nếu kết quả rỗng → fallback\n",
        "    if pred.strip() == \"\":\n",
        "        return text\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "uz3RoJduLDOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pp(filtered_output, real_tweet):\n",
        "    filtered_output = ' '.join(filtered_output.split())\n",
        "    if len(real_tweet.split()) < 2:\n",
        "        filtered_output = real_tweet\n",
        "    else:\n",
        "        if len(filtered_output.split()) == 1:\n",
        "            if filtered_output.endswith(\"..\"):\n",
        "                if real_tweet.startswith(\" \"):\n",
        "                    st = real_tweet.find(filtered_output)\n",
        "                    fl = real_tweet.find(\"  \")\n",
        "                    if fl != -1 and fl < st:\n",
        "                        filtered_output = re.sub(r'(\\.)\\1{2,}', '', filtered_output)\n",
        "                    else:\n",
        "                        filtered_output = re.sub(r'(\\.)\\1{2,}', '.', filtered_output)\n",
        "                else:\n",
        "                    st = real_tweet.find(filtered_output)\n",
        "                    fl = real_tweet.find(\"  \")\n",
        "                    if fl != -1 and fl < st:\n",
        "                        filtered_output = re.sub(r'(\\.)\\1{2,}', '.', filtered_output)\n",
        "                    else:\n",
        "                        filtered_output = re.sub(r'(\\.)\\1{2,}', '..', filtered_output)\n",
        "                return filtered_output\n",
        "            if filtered_output.endswith('!!'):\n",
        "                if real_tweet.startswith(\" \"):\n",
        "                    st = real_tweet.find(filtered_output)\n",
        "                    fl = real_tweet.find(\"  \")\n",
        "                    if fl != -1 and fl < st:\n",
        "                        filtered_output = re.sub(r'(\\!)\\1{2,}', '', filtered_output)\n",
        "                    else:\n",
        "                        filtered_output = re.sub(r'(\\!)\\1{2,}', '!', filtered_output)\n",
        "                else:\n",
        "                    st = real_tweet.find(filtered_output)\n",
        "                    fl = real_tweet.find(\"  \")\n",
        "                    if fl != -1 and fl < st:\n",
        "                        filtered_output = re.sub(r'(\\!)\\1{2,}', '!', filtered_output)\n",
        "                    else:\n",
        "                        filtered_output = re.sub(r'(\\!)\\1{2,}', '!!', filtered_output)\n",
        "                return filtered_output\n",
        "\n",
        "        if real_tweet.startswith(\" \"):\n",
        "            filtered_output = filtered_output.strip()\n",
        "            text_annotetor = ' '.join(real_tweet.split())\n",
        "            start = text_annotetor.find(filtered_output)\n",
        "            end = start + len(filtered_output)\n",
        "            start -= 0\n",
        "            end += 2\n",
        "            flag = real_tweet.find(\"  \")\n",
        "            if flag < start:\n",
        "                filtered_output = real_tweet[start:end]\n",
        "\n",
        "        if \"  \" in real_tweet and not real_tweet.startswith(\" \"):\n",
        "            filtered_output = filtered_output.strip()\n",
        "            text_annotetor = re.sub(\" {2,}\", \" \", real_tweet)\n",
        "            start = text_annotetor.find(filtered_output)\n",
        "            end = start + len(filtered_output)\n",
        "            start -= 0\n",
        "            end += 2\n",
        "            flag = real_tweet.find(\"  \")\n",
        "            if flag < start:\n",
        "                filtered_output = real_tweet[start:end]\n",
        "    return filtered_output\n"
      ],
      "metadata": {
        "id": "5emPLnaOs6p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "\n",
        "for row in test_df.itertuples():\n",
        "    text = row.text\n",
        "    sent = row.sentiment\n",
        "\n",
        "    enc = tokenizer(\n",
        "        sent,\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    input_ids = torch.tensor([enc[\"input_ids\"]]).to(device)\n",
        "    attn = torch.tensor([enc[\"attention_mask\"]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        s1, e1 = model1(input_ids, attn)\n",
        "        s2, e2 = model2(input_ids, attn)\n",
        "\n",
        "    # ENSEMBLE\n",
        "    alpha = 0.75  # ưu tiên model2\n",
        "\n",
        "    start_logits = alpha * s2 + (1 - alpha) * s1\n",
        "    end_logits   = alpha * e2 + (1 - alpha) * e1\n",
        "\n",
        "\n",
        "    ps = start_logits.argmax(-1).item()\n",
        "    pe = end_logits.argmax(-1).item()\n",
        "\n",
        "    pred = decode_span(text, ps, pe, enc[\"offset_mapping\"])\n",
        "\n",
        "    # Neutral rule\n",
        "    if sent == \"neutral\":\n",
        "        pred = text\n",
        "    else:\n",
        "        pred = pp(pred, text)\n",
        "\n",
        "    preds.append(pred)\n",
        "\n",
        "# Create submission\n",
        "submission = pd.DataFrame({\n",
        "    \"textID\": test_df[\"textID\"],\n",
        "    \"selected_text\": preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"File 'submission.csv' đã được tạo!\")\n",
        "submission.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-21T07:13:21.046398Z",
          "iopub.execute_input": "2025-11-21T07:13:21.046930Z",
          "iopub.status.idle": "2025-11-21T07:14:31.151398Z",
          "shell.execute_reply.started": "2025-11-21T07:13:21.046909Z",
          "shell.execute_reply": "2025-11-21T07:14:31.150637Z"
        },
        "id": "zcl2C9QzrAOZ",
        "outputId": "48cc0f85-cdbe-49b3-e699-e1616997c15d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "File 'submission.csv' đã được tạo!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       textID                                      selected_text\n0  f87dea47db  Last session of the day  http://twitpic.com/67ezh\n1  96d74cb729  exciting                                         \n2  eee518ae67  shame!                                           \n3  01082688c6  happy bday!                                      \n4  33987a8ee5  I like it!!                                      ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>selected_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>Last session of the day  http://twitpic.com/67ezh</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>exciting</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>shame!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>happy bday!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>I like it!!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reranking"
      ],
      "metadata": {
        "id": "R2uA0nCyUisM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-26T14:33:13.058844Z",
          "iopub.execute_input": "2025-11-26T14:33:13.059449Z",
          "iopub.status.idle": "2025-11-26T14:33:17.239017Z",
          "shell.execute_reply.started": "2025-11-26T14:33:13.059423Z",
          "shell.execute_reply": "2025-11-26T14:33:17.238296Z"
        },
        "id": "l0bqDgp4UMss",
        "outputId": "54ddaa8c-fe21-4acd-fa99-9dc1b6b0c0f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Using device: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = RobertaSpanModel().to(device)\n",
        "model2 = RobertaSpanModel().to(device)\n",
        "\n",
        "model1.load_state_dict(torch.load(\"/kaggle/input/last-epoch-mode/last_epoch_model.pt\"))\n",
        "model2.load_state_dict(torch.load(\"/kaggle/input/robertav2/robertaV2.pt\"))\n",
        "\n",
        "model1.eval()\n",
        "model2.eval()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-26T14:34:32.954155Z",
          "iopub.execute_input": "2025-11-26T14:34:32.955072Z",
          "iopub.status.idle": "2025-11-26T14:35:11.407773Z",
          "shell.execute_reply.started": "2025-11-26T14:34:32.955034Z",
          "shell.execute_reply": "2025-11-26T14:35:11.407035Z"
        },
        "id": "2k4Bfvz0UMss",
        "outputId": "84816fbf-7424-4984-f243-10913b0f9237",
        "colab": {
          "referenced_widgets": [
            "99cf8dcc6a2e47da80bd3fd5be125722"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-11-26 14:34:40.917457: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764167681.158031      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764167681.224667      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99cf8dcc6a2e47da80bd3fd5be125722"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "RobertaSpanModel(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (start_classifier): Linear(in_features=768, out_features=1, bias=True)\n  (end_classifier): Linear(in_features=768, out_features=1, bias=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "DATA_PATH = \"/kaggle/input/tweet-sentiment-extraction\"\n",
        "\n",
        "train_df = pd.read_csv(f\"{DATA_PATH}/train.csv\")\n",
        "test_df  = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
        "print(train_df.shape, test_df.shape)\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-26T14:35:17.701851Z",
          "iopub.execute_input": "2025-11-26T14:35:17.703163Z",
          "iopub.status.idle": "2025-11-26T14:35:17.876054Z",
          "shell.execute_reply.started": "2025-11-26T14:35:17.703124Z",
          "shell.execute_reply": "2025-11-26T14:35:17.875355Z"
        },
        "id": "7crbK-cNUMss",
        "outputId": "3b539afc-7291-406e-f91f-7fba47e88cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "(27481, 4) (3534, 3)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment  \n0  I`d have responded, if I were going   neutral  \n1                             Sooo SAD  negative  \n2                          bullying me  negative  \n3                       leave me alone  negative  \n4                        Sons of ****,  negative  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "def clean_text_safe(s):\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    s = s.strip()\n",
        "    return s\n",
        "train_df[\"text\"] = train_df[\"text\"].astype(str).apply(clean_text_safe)\n",
        "train_df[\"selected_text\"] = train_df[\"selected_text\"].astype(str).apply(clean_text_safe)\n",
        "test_df[\"text\"] = test_df[\"text\"].astype(str).apply(clean_text_safe)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-26T14:35:58.142866Z",
          "iopub.execute_input": "2025-11-26T14:35:58.143593Z",
          "iopub.status.idle": "2025-11-26T14:35:58.173837Z",
          "shell.execute_reply.started": "2025-11-26T14:35:58.143566Z",
          "shell.execute_reply": "2025-11-26T14:35:58.173199Z"
        },
        "id": "Dneg2HM5UMss"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard(str1, str2):\n",
        "    a = set(str1.lower().split())\n",
        "    b = set(str2.lower().split())\n",
        "    if len(a) == 0 and len(b) == 0:\n",
        "        return 1.0\n",
        "    return float(len(a & b)) / len(a | b)\n"
      ],
      "metadata": {
        "id": "Jg97JjxVU82N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_span(text, start_idx, end_idx, offsets):\n",
        "\n",
        "    if start_idx is None or end_idx is None:\n",
        "        return text\n",
        "    if start_idx < 0 or end_idx >= len(offsets):\n",
        "        return text\n",
        "    if end_idx < start_idx:\n",
        "        end_idx = start_idx\n",
        "\n",
        "    start_char = offsets[start_idx][0]\n",
        "    end_char = offsets[end_idx][1]\n",
        "\n",
        "    if start_char is None or end_char is None:\n",
        "        return text\n",
        "\n",
        "    pred = text[start_char:end_char]\n",
        "\n",
        "    # Nếu kết quả rỗng → fallback\n",
        "    if pred.strip() == \"\":\n",
        "        return text\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "x34BGyHCU9SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_top_n_spans_ensemble(text, sentiment, model1, model2, tokenizer, n=5):\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "\n",
        "    enc = tokenizer(\n",
        "        sentiment,\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    input_ids = torch.tensor([enc[\"input_ids\"]]).to(device)\n",
        "    attn = torch.tensor([enc[\"attention_mask\"]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        s1, e1 = model1(input_ids, attn)\n",
        "        s2, e2 = model2(input_ids, attn)\n",
        "\n",
        "    # Ensemble logits (có thể chỉnh alpha nếu muốn)\n",
        "    alpha = 0.75  # ưu tiên model2\n",
        "    start_logits = alpha * s2 + (1 - alpha) * s1\n",
        "    end_logits   = alpha * e2 + (1 - alpha) * e1\n",
        "\n",
        "    start_prob = torch.softmax(start_logits, dim=1)[0]\n",
        "    end_prob   = torch.softmax(end_logits, dim=1)[0]\n",
        "\n",
        "    start_top = torch.topk(start_prob, n).indices\n",
        "    end_top   = torch.topk(end_prob, n).indices\n",
        "\n",
        "    spans = {}\n",
        "\n",
        "    for s in start_top:\n",
        "        for e in end_top:\n",
        "            if e >= s and e - s < 20:\n",
        "                span = decode_span(text, s.item(), e.item(), enc[\"offset_mapping\"])\n",
        "                score = (start_prob[s] + end_prob[e]).item()\n",
        "\n",
        "                # Tránh span bị trùng → giữ điểm cao nhất\n",
        "                if span not in spans or spans[span] < score:\n",
        "                    spans[span] = score\n",
        "\n",
        "    spans = sorted(spans.items(), key=lambda x: x[1], reverse=True)\n",
        "    return spans[:n]"
      ],
      "metadata": {
        "id": "AGmyeJlQU_QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rerank_data = []\n",
        "\n",
        "for idx, row in train_df.iterrows():\n",
        "    text = row.text\n",
        "    sent = row.sentiment\n",
        "    gt = row.selected_text\n",
        "\n",
        "    candidates = generate_top_n_spans_ensemble(\n",
        "        text, sent, model1, model2, tokenizer, n=5\n",
        "    )\n",
        "\n",
        "    for span, base_score in candidates:\n",
        "        rerank_data.append({\n",
        "            \"text\": text,\n",
        "            \"sentiment\": sent,\n",
        "            \"candidate\": span,\n",
        "            \"base_score\": base_score,\n",
        "            \"jaccard\": jaccard(span, gt)\n",
        "        })\n",
        "\n",
        "rerank_df = pd.DataFrame(rerank_data)\n",
        "rerank_df.to_csv(\"rerank_train.csv\", index=False)"
      ],
      "metadata": {
        "id": "-X7NtvzLVELt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rerank_df = pd.read_csv(\"rerank_train.csv\")\n",
        "print(rerank_df.shape)\n",
        "rerank_df.head(10)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-26T09:26:35.326056Z",
          "iopub.execute_input": "2025-11-26T09:26:35.326347Z",
          "iopub.status.idle": "2025-11-26T09:26:35.610215Z",
          "shell.execute_reply.started": "2025-11-26T09:26:35.326324Z",
          "shell.execute_reply": "2025-11-26T09:26:35.609388Z"
        },
        "id": "2c2Lei-tUMst",
        "outputId": "4fe8cdce-e305-467d-c01b-25ab34a3a30f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "(136616, 5)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                            text sentiment  \\\n0            I`d have responded, if I were going   neutral   \n1            I`d have responded, if I were going   neutral   \n2            I`d have responded, if I were going   neutral   \n3            I`d have responded, if I were going   neutral   \n4            I`d have responded, if I were going   neutral   \n5  Sooo SAD I will miss you here in San Diego!!!  negative   \n6  Sooo SAD I will miss you here in San Diego!!!  negative   \n7  Sooo SAD I will miss you here in San Diego!!!  negative   \n8  Sooo SAD I will miss you here in San Diego!!!  negative   \n9  Sooo SAD I will miss you here in San Diego!!!  negative   \n\n                                       candidate  base_score   jaccard  \n0            I`d have responded, if I were going    1.998756  1.000000  \n1                            I`d have responded,    1.000430  0.428571  \n2                  I`d have responded, if I were    0.999887  0.857143  \n3                         I`d have responded, if    0.999848  0.571429  \n4                                              I    0.999845  0.142857  \n5                                       Sooo SAD    1.351530  1.000000  \n6                                            SAD    1.119102  0.500000  \n7                                        ooo SAD    0.761564  0.333333  \n8  Sooo SAD I will miss you here in San Diego!!!    0.734349  0.200000  \n9                           Sooo SAD I will miss    0.636720  0.400000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>candidate</th>\n      <th>base_score</th>\n      <th>jaccard</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>I`d have responded, if I were going</td>\n      <td>1.998756</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>I`d have responded,</td>\n      <td>1.000430</td>\n      <td>0.428571</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>I`d have responded, if I were</td>\n      <td>0.999887</td>\n      <td>0.857143</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>I`d have responded, if</td>\n      <td>0.999848</td>\n      <td>0.571429</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>I</td>\n      <td>0.999845</td>\n      <td>0.142857</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n      <td>Sooo SAD</td>\n      <td>1.351530</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n      <td>SAD</td>\n      <td>1.119102</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n      <td>ooo SAD</td>\n      <td>0.761564</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>0.734349</td>\n      <td>0.200000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>negative</td>\n      <td>Sooo SAD I will miss</td>\n      <td>0.636720</td>\n      <td>0.400000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class RerankDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        # Ép kiểu + xử lý NaN để tránh lỗi\n",
        "        self.texts = df[\"text\"].fillna(\"\").astype(str).tolist()\n",
        "        self.sentiments = df[\"sentiment\"].fillna(\"\").astype(str).tolist()\n",
        "        self.candidates = df[\"candidate\"].fillna(\"\").astype(str).tolist()\n",
        "        self.labels = df[\"jaccard\"].fillna(0).tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        combined = (\n",
        "            self.sentiments[idx] + \" \" +\n",
        "            self.texts[idx] + \" [SEP] \" +\n",
        "            self.candidates[idx]\n",
        "        )\n",
        "\n",
        "        enc = self.tokenizer(\n",
        "            combined,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        }"
      ],
      "metadata": {
        "id": "hnF_jzZlVLnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "from torch.utils.data import DataLoader\n",
        "class RobertaRerankModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.roberta = AutoModel.from_pretrained(\"roberta-base\")\n",
        "        self.fc = nn.Linear(self.roberta.config.hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls = out.last_hidden_state[:, 0, :]\n",
        "        return self.fc(cls).squeeze(-1)\n"
      ],
      "metadata": {
        "id": "avX_uBsyVMKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rerank_dataset = RerankDataset(rerank_df, tokenizer)\n",
        "rerank_loader = DataLoader(rerank_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "rerank_model = RobertaRerankModel().to(device)\n",
        "optimizer = torch.optim.AdamW(rerank_model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "for epoch in range(3):\n",
        "    rerank_model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(rerank_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = rerank_model(\n",
        "            batch[\"input_ids\"].to(device),\n",
        "            batch[\"attention_mask\"].to(device)\n",
        "        ).squeeze()\n",
        "\n",
        "        loss = loss_fn(outputs, batch[\"label\"].to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if step % 200 == 0:\n",
        "            print(f\"Epoch {epoch+1} | Step {step} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1} AVG Loss: {total_loss / len(rerank_loader):.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-26T09:40:00.922009Z",
          "iopub.execute_input": "2025-11-26T09:40:00.922567Z",
          "iopub.status.idle": "2025-11-26T12:20:47.418547Z",
          "shell.execute_reply.started": "2025-11-26T09:40:00.922542Z",
          "shell.execute_reply": "2025-11-26T12:20:47.417817Z"
        },
        "id": "sSbjWH48UMsv",
        "outputId": "f8c743ad-c59a-4ab2-af36-53fa771cee24"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 | Step 0 | Loss: 0.7180\nEpoch 1 | Step 200 | Loss: 0.0909\nEpoch 1 | Step 400 | Loss: 0.1487\nEpoch 1 | Step 600 | Loss: 0.0672\nEpoch 1 | Step 800 | Loss: 0.0746\nEpoch 1 | Step 1000 | Loss: 0.1549\nEpoch 1 | Step 1200 | Loss: 0.0947\nEpoch 1 | Step 1400 | Loss: 0.0718\nEpoch 1 | Step 1600 | Loss: 0.0232\nEpoch 1 | Step 1800 | Loss: 0.1048\nEpoch 1 | Step 2000 | Loss: 0.0550\nEpoch 1 | Step 2200 | Loss: 0.0408\nEpoch 1 | Step 2400 | Loss: 0.0530\nEpoch 1 | Step 2600 | Loss: 0.0658\nEpoch 1 | Step 2800 | Loss: 0.0420\nEpoch 1 | Step 3000 | Loss: 0.0687\nEpoch 1 | Step 3200 | Loss: 0.0417\nEpoch 1 | Step 3400 | Loss: 0.0694\nEpoch 1 | Step 3600 | Loss: 0.0503\nEpoch 1 | Step 3800 | Loss: 0.1097\nEpoch 1 | Step 4000 | Loss: 0.0716\nEpoch 1 | Step 4200 | Loss: 0.0731\nEpoch 1 | Step 4400 | Loss: 0.1056\nEpoch 1 | Step 4600 | Loss: 0.0603\nEpoch 1 | Step 4800 | Loss: 0.0448\nEpoch 1 | Step 5000 | Loss: 0.0802\nEpoch 1 | Step 5200 | Loss: 0.0463\nEpoch 1 | Step 5400 | Loss: 0.0352\nEpoch 1 | Step 5600 | Loss: 0.0403\nEpoch 1 | Step 5800 | Loss: 0.0646\nEpoch 1 | Step 6000 | Loss: 0.1229\nEpoch 1 | Step 6200 | Loss: 0.0588\nEpoch 1 | Step 6400 | Loss: 0.0706\nEpoch 1 | Step 6600 | Loss: 0.0576\nEpoch 1 | Step 6800 | Loss: 0.0718\nEpoch 1 | Step 7000 | Loss: 0.0782\nEpoch 1 | Step 7200 | Loss: 0.0600\nEpoch 1 | Step 7400 | Loss: 0.0279\nEpoch 1 | Step 7600 | Loss: 0.0528\nEpoch 1 | Step 7800 | Loss: 0.0466\nEpoch 1 | Step 8000 | Loss: 0.0286\nEpoch 1 | Step 8200 | Loss: 0.0361\nEpoch 1 | Step 8400 | Loss: 0.0797\nEpoch 1 AVG Loss: 0.0612\nEpoch 2 | Step 0 | Loss: 0.0501\nEpoch 2 | Step 200 | Loss: 0.0609\nEpoch 2 | Step 400 | Loss: 0.0588\nEpoch 2 | Step 600 | Loss: 0.0551\nEpoch 2 | Step 800 | Loss: 0.0689\nEpoch 2 | Step 1000 | Loss: 0.0563\nEpoch 2 | Step 1200 | Loss: 0.0752\nEpoch 2 | Step 1400 | Loss: 0.0492\nEpoch 2 | Step 1600 | Loss: 0.0325\nEpoch 2 | Step 1800 | Loss: 0.0473\nEpoch 2 | Step 2000 | Loss: 0.0766\nEpoch 2 | Step 2200 | Loss: 0.0634\nEpoch 2 | Step 2400 | Loss: 0.0118\nEpoch 2 | Step 2600 | Loss: 0.0665\nEpoch 2 | Step 2800 | Loss: 0.0232\nEpoch 2 | Step 3000 | Loss: 0.0094\nEpoch 2 | Step 3200 | Loss: 0.0374\nEpoch 2 | Step 3400 | Loss: 0.0777\nEpoch 2 | Step 3600 | Loss: 0.0554\nEpoch 2 | Step 3800 | Loss: 0.0677\nEpoch 2 | Step 4000 | Loss: 0.0317\nEpoch 2 | Step 4200 | Loss: 0.0253\nEpoch 2 | Step 4400 | Loss: 0.1413\nEpoch 2 | Step 4600 | Loss: 0.0494\nEpoch 2 | Step 4800 | Loss: 0.0454\nEpoch 2 | Step 5000 | Loss: 0.0696\nEpoch 2 | Step 5200 | Loss: 0.0990\nEpoch 2 | Step 5400 | Loss: 0.0253\nEpoch 2 | Step 5600 | Loss: 0.0422\nEpoch 2 | Step 5800 | Loss: 0.0325\nEpoch 2 | Step 6000 | Loss: 0.1260\nEpoch 2 | Step 6200 | Loss: 0.0346\nEpoch 2 | Step 6400 | Loss: 0.0307\nEpoch 2 | Step 6600 | Loss: 0.0931\nEpoch 2 | Step 6800 | Loss: 0.0369\nEpoch 2 | Step 7000 | Loss: 0.0154\nEpoch 2 | Step 7200 | Loss: 0.0698\nEpoch 2 | Step 7400 | Loss: 0.0503\nEpoch 2 | Step 7600 | Loss: 0.0477\nEpoch 2 | Step 7800 | Loss: 0.0478\nEpoch 2 | Step 8000 | Loss: 0.0542\nEpoch 2 | Step 8200 | Loss: 0.0175\nEpoch 2 | Step 8400 | Loss: 0.0571\nEpoch 2 AVG Loss: 0.0497\nEpoch 3 | Step 0 | Loss: 0.0652\nEpoch 3 | Step 200 | Loss: 0.0327\nEpoch 3 | Step 400 | Loss: 0.0189\nEpoch 3 | Step 600 | Loss: 0.0309\nEpoch 3 | Step 800 | Loss: 0.0066\nEpoch 3 | Step 1000 | Loss: 0.0650\nEpoch 3 | Step 1200 | Loss: 0.0377\nEpoch 3 | Step 1400 | Loss: 0.0418\nEpoch 3 | Step 1600 | Loss: 0.0381\nEpoch 3 | Step 1800 | Loss: 0.0497\nEpoch 3 | Step 2000 | Loss: 0.0433\nEpoch 3 | Step 2200 | Loss: 0.0455\nEpoch 3 | Step 2400 | Loss: 0.0219\nEpoch 3 | Step 2600 | Loss: 0.0136\nEpoch 3 | Step 2800 | Loss: 0.0353\nEpoch 3 | Step 3000 | Loss: 0.0421\nEpoch 3 | Step 3200 | Loss: 0.0765\nEpoch 3 | Step 3400 | Loss: 0.0333\nEpoch 3 | Step 3600 | Loss: 0.0261\nEpoch 3 | Step 3800 | Loss: 0.0612\nEpoch 3 | Step 4000 | Loss: 0.0266\nEpoch 3 | Step 4200 | Loss: 0.0393\nEpoch 3 | Step 4400 | Loss: 0.0498\nEpoch 3 | Step 4600 | Loss: 0.0734\nEpoch 3 | Step 4800 | Loss: 0.0786\nEpoch 3 | Step 5000 | Loss: 0.0398\nEpoch 3 | Step 5200 | Loss: 0.0363\nEpoch 3 | Step 5400 | Loss: 0.0275\nEpoch 3 | Step 5600 | Loss: 0.0284\nEpoch 3 | Step 5800 | Loss: 0.0085\nEpoch 3 | Step 6000 | Loss: 0.0155\nEpoch 3 | Step 6200 | Loss: 0.0677\nEpoch 3 | Step 6400 | Loss: 0.0079\nEpoch 3 | Step 6600 | Loss: 0.0549\nEpoch 3 | Step 6800 | Loss: 0.0253\nEpoch 3 | Step 7000 | Loss: 0.0181\nEpoch 3 | Step 7200 | Loss: 0.0494\nEpoch 3 | Step 7400 | Loss: 0.0126\nEpoch 3 | Step 7600 | Loss: 0.0172\nEpoch 3 | Step 7800 | Loss: 0.0271\nEpoch 3 | Step 8000 | Loss: 0.0447\nEpoch 3 | Step 8200 | Loss: 0.0644\nEpoch 3 | Step 8400 | Loss: 0.0194\nEpoch 3 AVG Loss: 0.0413\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(rerank_model.state_dict(), \"rerank_model.pt\")\n",
        "print(\"Đã lưu model rerank vào rerank_model.pt\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-26T17:49:42.035594Z",
          "iopub.execute_input": "2025-11-26T17:49:42.036169Z",
          "iopub.status.idle": "2025-11-26T17:49:42.706446Z",
          "shell.execute_reply.started": "2025-11-26T17:49:42.036145Z",
          "shell.execute_reply": "2025-11-26T17:49:42.705797Z"
        },
        "id": "2Ff2Z3MCUMsw",
        "outputId": "8385cb56-91d5-4e4e-abb3-f8be8d144661"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Đã lưu model rerank vào rerank_model.pt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "rerank_model = RobertaRerankModel().to(device)\n",
        "rerank_model.load_state_dict(torch.load(\"/kaggle/input/rerank-modelv1/rerank_modelV1.pt\"))\n",
        "rerank_model.eval()\n",
        "print(\"Loaded rerank model\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-26T19:06:40.585446Z",
          "iopub.execute_input": "2025-11-26T19:06:40.586311Z",
          "iopub.status.idle": "2025-11-26T19:06:46.682479Z",
          "shell.execute_reply.started": "2025-11-26T19:06:40.586281Z",
          "shell.execute_reply": "2025-11-26T19:06:46.681839Z"
        },
        "id": "BCr5OPJOUMsx",
        "outputId": "d98b28a9-f30d-4d51-fb21-89014611094d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Loaded rerank model\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_span(text, start_idx, end_idx, offsets):\n",
        "\n",
        "    if start_idx is None or end_idx is None:\n",
        "        return text\n",
        "    if start_idx < 0 or end_idx >= len(offsets):\n",
        "        return text\n",
        "    if end_idx < start_idx:\n",
        "        end_idx = start_idx\n",
        "\n",
        "    start_char = offsets[start_idx][0]\n",
        "    end_char = offsets[end_idx][1]\n",
        "\n",
        "    if start_char is None or end_char is None:\n",
        "        return text\n",
        "\n",
        "    pred = text[start_char:end_char]\n",
        "\n",
        "    # Nếu kết quả rỗng → fallback\n",
        "    if pred.strip() == \"\":\n",
        "        return text\n",
        "\n",
        "    return pred"
      ],
      "metadata": {
        "id": "isYD-ZmZVXzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_top_n_spans_ensemble(text, sentiment, model1, model2, tokenizer, n=5):\n",
        "    \"\"\"\n",
        "    Sinh top-N span candidates chất lượng cao bằng ensemble + joint probability\n",
        "    \"\"\"\n",
        "\n",
        "    enc = tokenizer(\n",
        "        sentiment,\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    input_ids = torch.tensor([enc[\"input_ids\"]]).to(device)\n",
        "    attn = torch.tensor([enc[\"attention_mask\"]]).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        s1, e1 = model1(input_ids, attn)\n",
        "        s2, e2 = model2(input_ids, attn)\n",
        "\n",
        "    # ==== Ensemble logits ====\n",
        "    alpha = 0.75\n",
        "    start_logits = alpha * s2 + (1 - alpha) * s1\n",
        "    end_logits   = alpha * e2 + (1 - alpha) * e1\n",
        "\n",
        "    # ==== Convert to probability ====\n",
        "    start_prob = torch.softmax(start_logits, dim=1)[0]\n",
        "    end_prob   = torch.softmax(end_logits, dim=1)[0]\n",
        "\n",
        "    # === Lấy nhiều hơn để lọc sau ===\n",
        "    k = max(n * 3, 10)\n",
        "    start_top = torch.topk(start_prob, k).indices\n",
        "    end_top   = torch.topk(end_prob, k).indices\n",
        "\n",
        "    spans = []\n",
        "\n",
        "    for s in start_top:\n",
        "        for e in end_top:\n",
        "            if e < s:\n",
        "                continue\n",
        "\n",
        "            # giới hạn độ dài span\n",
        "            if e - s > 30:\n",
        "                continue\n",
        "\n",
        "            span = decode_span(text, s.item(), e.item(), enc[\"offset_mapping\"])\n",
        "\n",
        "            if span.strip() == \"\":\n",
        "                continue\n",
        "\n",
        "            # loại span quá ngắn\n",
        "            if len(span.split()) == 1 and len(span) < 3:\n",
        "                continue\n",
        "\n",
        "            # loại span rác phổ biến\n",
        "            if span.lower().strip() in [\"i\", \"you\", \"and\", \"the\", \"to\"]:\n",
        "                continue\n",
        "\n",
        "            # === JOINT SCORE (log probability) ===\n",
        "            score = torch.log(start_prob[s] + 1e-12) + torch.log(end_prob[e] + 1e-12)\n",
        "            score = score.item()\n",
        "\n",
        "            spans.append((span, score))\n",
        "\n",
        "    # Nếu không còn span hợp lệ\n",
        "    if not spans:\n",
        "        return [(text, 0.0)]\n",
        "\n",
        "    # Sắp xếp theo score giảm dần\n",
        "    spans = sorted(spans, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Loại span trùng nhau\n",
        "    unique = []\n",
        "    seen = set()\n",
        "    for span, score in spans:\n",
        "        if span not in seen:\n",
        "            unique.append((span, score))\n",
        "            seen.add(span)\n",
        "        if len(unique) >= n:\n",
        "            break\n",
        "\n",
        "    return unique"
      ],
      "metadata": {
        "id": "hLC0fIF3Vab3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rerank_span_score(text, sentiment, candidate):\n",
        "    combined = sentiment + \" \" + text + \" [SEP] \" + candidate\n",
        "\n",
        "    enc = tokenizer(\n",
        "        combined,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        score = rerank_model(\n",
        "            enc[\"input_ids\"].to(device),\n",
        "            enc[\"attention_mask\"].to(device)\n",
        "        ).squeeze().item()\n",
        "\n",
        "    return score\n"
      ],
      "metadata": {
        "id": "AOS0KzPGVa-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pp(filtered_output, real_tweet):\n",
        "    filtered_output = ' '.join(filtered_output.split())\n",
        "    if len(real_tweet.split()) < 2:\n",
        "        filtered_output = real_tweet\n",
        "    else:\n",
        "        if len(filtered_output.split()) == 1:\n",
        "            if filtered_output.endswith(\"..\"):\n",
        "                if real_tweet.startswith(\" \"):\n",
        "                    st = real_tweet.find(filtered_output)\n",
        "                    fl = real_tweet.find(\"  \")\n",
        "                    if fl != -1 and fl < st:\n",
        "                        filtered_output = re.sub(r'(\\.)\\1{2,}', '', filtered_output)\n",
        "                    else:\n",
        "                        filtered_output = re.sub(r'(\\.)\\1{2,}', '.', filtered_output)\n",
        "                else:\n",
        "                    st = real_tweet.find(filtered_output)\n",
        "                    fl = real_tweet.find(\"  \")\n",
        "                    if fl != -1 and fl < st:\n",
        "                        filtered_output = re.sub(r'(\\.)\\1{2,}', '.', filtered_output)\n",
        "                    else:\n",
        "                        filtered_output = re.sub(r'(\\.)\\1{2,}', '..', filtered_output)\n",
        "                return filtered_output\n",
        "            if filtered_output.endswith('!!'):\n",
        "                if real_tweet.startswith(\" \"):\n",
        "                    st = real_tweet.find(filtered_output)\n",
        "                    fl = real_tweet.find(\"  \")\n",
        "                    if fl != -1 and fl < st:\n",
        "                        filtered_output = re.sub(r'(\\!)\\1{2,}', '', filtered_output)\n",
        "                    else:\n",
        "                        filtered_output = re.sub(r'(\\!)\\1{2,}', '!', filtered_output)\n",
        "                else:\n",
        "                    st = real_tweet.find(filtered_output)\n",
        "                    fl = real_tweet.find(\"  \")\n",
        "                    if fl != -1 and fl < st:\n",
        "                        filtered_output = re.sub(r'(\\!)\\1{2,}', '!', filtered_output)\n",
        "                    else:\n",
        "                        filtered_output = re.sub(r'(\\!)\\1{2,}', '!!', filtered_output)\n",
        "                return filtered_output\n",
        "\n",
        "        if real_tweet.startswith(\" \"):\n",
        "            filtered_output = filtered_output.strip()\n",
        "            text_annotetor = ' '.join(real_tweet.split())\n",
        "            start = text_annotetor.find(filtered_output)\n",
        "            end = start + len(filtered_output)\n",
        "            start -= 0\n",
        "            end += 2\n",
        "            flag = real_tweet.find(\"  \")\n",
        "            if flag < start:\n",
        "                filtered_output = real_tweet[start:end]\n",
        "\n",
        "        if \"  \" in real_tweet and not real_tweet.startswith(\" \"):\n",
        "            filtered_output = filtered_output.strip()\n",
        "            text_annotetor = re.sub(\" {2,}\", \" \", real_tweet)\n",
        "            start = text_annotetor.find(filtered_output)\n",
        "            end = start + len(filtered_output)\n",
        "            start -= 0\n",
        "            end += 2\n",
        "            flag = real_tweet.find(\"  \")\n",
        "            if flag < start:\n",
        "                filtered_output = real_tweet[start:end]\n",
        "    return filtered_output\n"
      ],
      "metadata": {
        "id": "BvdVQp7wVcnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "\n",
        "for row in test_df.itertuples():\n",
        "    text = row.text\n",
        "    sent = row.sentiment\n",
        "\n",
        "    if sent == \"neutral\":\n",
        "        preds.append(text)\n",
        "        continue\n",
        "\n",
        "    candidates = generate_top_n_spans_ensemble(\n",
        "        text, sent, model1, model2, tokenizer, n=5\n",
        "    )\n",
        "\n",
        "    # Span tốt nhất theo BASE model\n",
        "    base_best_span = candidates[0][0]\n",
        "    base_best_score = candidates[0][1]\n",
        "\n",
        "    best_span = base_best_span\n",
        "    best_score = -1e9\n",
        "\n",
        "    # Kiểm tra độ tự tin của base\n",
        "    if len(candidates) > 1:\n",
        "        gap = candidates[0][1] - candidates[1][1]\n",
        "    else:\n",
        "        gap = 1.0\n",
        "\n",
        "    USE_RERANK = gap < 0.1  # chỉ rerank nếu base không chắc\n",
        "\n",
        "    if USE_RERANK:\n",
        "        for span, base_score in candidates:\n",
        "            r_score = rerank_span_score(text, sent, span)\n",
        "\n",
        "            # giảm quyền rerank\n",
        "            final_score = 0.7 * base_score + 0.3 * r_score\n",
        "            if final_score > best_score:\n",
        "                best_score = final_score\n",
        "                best_span = span\n",
        "    else:\n",
        "        best_span = base_best_span\n",
        "\n",
        "    best_span = pp(best_span, text)\n",
        "    preds.append(best_span)\n"
      ],
      "metadata": {
        "id": "AHW8fYSrVkKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"textID\": test_df[\"textID\"],\n",
        "    \"selected_text\": preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Submission với RERANK đã tạo xong!\")\n",
        "submission.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-26T19:17:40.808494Z",
          "iopub.execute_input": "2025-11-26T19:17:40.808775Z",
          "iopub.status.idle": "2025-11-26T19:17:40.826904Z",
          "shell.execute_reply.started": "2025-11-26T19:17:40.808753Z",
          "shell.execute_reply": "2025-11-26T19:17:40.826311Z"
        },
        "id": "zsYFtUNwUMsy",
        "outputId": "97fe7cad-bc1d-420e-8ceb-80f603cf9fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Submission với RERANK đã tạo xong!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 57,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       textID                                      selected_text\n0  f87dea47db  Last session of the day  http://twitpic.com/67ezh\n1  96d74cb729                                           exciting\n2  eee518ae67                                             shame!\n3  01082688c6                                        happy bday!\n4  33987a8ee5                                        I like it!!",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>selected_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>Last session of the day  http://twitpic.com/67ezh</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>exciting</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>shame!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>happy bday!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>I like it!!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = [\n",
        "    \"RoBERTa Model 1\",\n",
        "    \"RoBERTa Model 2\",\n",
        "    \"Ensemble\",\n",
        "    \"Ensemble + Reranking\"\n",
        "]\n",
        "\n",
        "jaccard_scores = [\n",
        "    0.70870,\n",
        "    0.71166,\n",
        "    0.71584,\n",
        "    0.71830\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(models, jaccard_scores)\n",
        "\n",
        "plt.xlabel(\"Phiên bản mô hình\")\n",
        "plt.ylabel(\"Điểm Jaccard\")\n",
        "plt.title(\"So sánh hiệu quả các phiên bản mô hình\")\n",
        "\n",
        "plt.xticks()\n",
        "plt.ylim(0.705, 0.72)\n",
        "plt.grid(False)\n",
        "\n",
        "for bar, score in zip(bars, jaccard_scores):\n",
        "    plt.text(\n",
        "        bar.get_x() + bar.get_width() / 2,\n",
        "        bar.get_height(),\n",
        "        f\"{score:.5f}\",\n",
        "        ha='center',\n",
        "        va='bottom'\n",
        "    )\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-27T17:58:34.381642Z",
          "iopub.execute_input": "2025-11-27T17:58:34.381940Z",
          "iopub.status.idle": "2025-11-27T17:58:34.545916Z",
          "shell.execute_reply.started": "2025-11-27T17:58:34.381919Z",
          "shell.execute_reply": "2025-11-27T17:58:34.545335Z"
        },
        "id": "3-XPWvcOe520",
        "outputId": "a0ab7c6d-84f1-4139-f1ce-09fcfebfb666"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x500 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}